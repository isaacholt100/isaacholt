\input{../header.tex}

\let\oldforall\forall
\renewcommand{\forall}{\ \oldforall}

\let\oldexist\exists
\renewcommand{\exists}{\ \oldexist}

\newcommand\existu{\ \oldexist!}

\title{Mathematical Physics Course Notes}
\author{Isaac Holt}

\begin{document}

\input{../titletoc.tex}

\section{The action principle}

\subsection{Calculus of variatons}

\begin{definition}
	A \textbf{functional} is a map from a set of functions to $\mathbb{R}$, e.g. $f: (\mathbb{R} \rightarrow \mathbb{R}) \rightarrow \mathbb{R}$.
\end{definition}

\begin{definition}
	Let $y(t)$ be a function with fixed values at endpoints $a$ and $b$. $y$ is \textbf{stationary} for a functional $S$ if

	\[ \diff{S (y(t) + \epsilon z(t))}{\epsilon}\Big|_{\epsilon = 0} = 0 \]
	for every smooth (continuous derivative to every order) $z(t)$ such that $z(a) = z(b) = 0$.
\end{definition}

\begin{remark}
	Functions $y(t)$ may be referred to as \textbf{paths} and so functions that satisfy the above definition are referred to as \textbf{stationary paths}.
\end{remark}

\begin{definition}
	Let $S$ be an \textbf{action functional} (or just \textbf{action}). \textbf{The action principle} states that the paths described by particles are stationary paths of $S$.

	Mathematically, given a particle moving in one dimension with position given by $x(t)$, for arbitrary smooth small deformations $\delta x(t)$ around the true path $x(t)$ (the path the particle follows):

	\[ \delta S := S(x + \delta x) - S(x) = O({(\delta x)}^2) \]
\end{definition}

\begin{lemma}
	(Fundamental lemma of the calculus of variations) Let $f(x)$ be a continuous function in the interval $[a, b]$ such that

	\[ \int_a^b f(x) g(x) dx = 0 \]
	for every smooth function $g(x)$ in $[a, b]$ such that $g(a) = g(b) = 0$. Then $f(x) = 0 \forall x \in [a, b]$.
\end{lemma}

\begin{definition}
	Let $L(r, s)$ be a function of two real variables. If a functional $S$ can be expressed as the time integral of $L$, i.e. if

	\[ S(x) = \int_{t_0}^{t_1} L(x(t), \dot{x}(t)) dt \]
	then $L$ is called a \textbf{Lagrangian}.
\end{definition}

\begin{definition}
	For a Lagrangian $L$, the \textbf{Euler-Lagrange equation} is given by

	\[ \diffp{L}{x} - \diff{}{t} \left( \diffp{L}{\dot{x}} \right) = 0 \]
	where

	\[ \diffp{L}{x} = \diffp{L(r, s)}{r} \Big|_{(r, s) = (x(t), \dot{x}(t))} \text{ \ and \ } \diffp{L}{\dot{x}} = \diffp{L(r, s)}{s} \Big|_{(r, s) = (x(t), \dot{x}(t))} \]
\end{definition}

\begin{remark}\label{rem:lagrangianParametersIndependent}
	The Lagrangian $L$ is just an ordinary function of (here) two independent parameters $(r, s)$t. When constructing the action, $L$ is evaluated at $(r, s) = (x(t), \dot{x}(t))$, but $r$ and $s$ as parameters in the definition of the Lagrangian are independent.

	So $\dot{x}$ is treated as a variable which does not depend on $x$:

	\[ \diffp{x}{\dot{x}} = \diffp{\dot{x}}{x} = 0 \]
\end{remark}

\begin{remark}
	The Euler-Lagrange equation only applies to one-dimensional cases.
\end{remark}

\subsection{Configuration space and generalised coordinates}

\begin{definition}
	\textbf{Configuration space}, denoted $C$, is the set of all possible (in principle) instantaneous configurations for a given a physical system.
\end{definition}

\begin{remark}
	This definition includes positions, but does not include velocities.
\end{remark}

\begin{remark}
	A configuration space must be constructed before a Lagrangian is constructed. The Lagrangian describes the dynamics of this configuration space.
\end{remark}

\begin{example}
	A particle moving in $\mathbb{R}^d$ has configuration space $\mathbb{R}^d$.
\end{example}

\begin{example}
	$N$ distinct particles moving in $\mathbb{R}^d$ have configuration space ${(\mathbb{R}^d)}^N = \mathbb{R}^{dN}$. The configuration space would still be $\mathbb{R}^{dN}$ if the particles were electrically charged, as the charge of the particles does not affect their positions, at least initially.
\end{example}

\begin{example}
	Two distinct particles joined by a rigid rod have configuration space $\mathbb{R}^{2d - 1}$. One particle has configuration space $\mathbb{R}^d$ and there are $d - 1$ angles that must specified to choose the position of the second particle relative to the other.
\end{example}

\begin{definition}
	Let $S$ be a physical system with configuration space $C$. Then $S$ has $\dim(C)$ \textbf{degrees of freedom}.
\end{definition}

\begin{remark}
	For every configuration space, any choice of coordinate system is valid, and the Lagrangian formalism holds regardless of this choice.
\end{remark}

\begin{definition}
	For a configuration space $C$, a set of coordinates in this space is called a set of \textbf{generalised coordinates}. Often generalized coordinates are represented with $q_i$, $i \in \{ 1, \dots, \dim(C) \}$ where $\underline{q}$ is the coordinate vector with components $q_i$.
\end{definition}

\begin{example}
	A particle moving in $\mathbb{R}^2$, with configuration space $\mathbb{R}^2$. We could use Cartesian or polar coordinates to describe the position of the particle in this space (both are equally valid).
\end{example}

\begin{definition}
	Let $C$ be a configuration space and let $\underline{q}(t) \in C$ be a path. For a Lagrangian function $L(\underline{q}, \underline{\dot{q}})$, the \textbf{Euler-Lagrange equations} state that

	\[ \diffp{L}{q_i} - \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) = 0 \quad \forall i \in \{ 1, \dots, \dim(C) \} \]
\end{definition}

\begin{remark}
	The Euler-Lagrange equations are valid in any coordinate system.
\end{remark}

\begin{remark}
	Similarly to the one-dimensional case:

	\[ \diffp{q_i}{\dot{q}_j} = \diffp{\dot{q}_i}{q_j} = 0 \]
	and

	\[ \diffp{q_i}{q_j} = \diffp{\dot{q}_i}{\dot{q}_j} = \delta_{ij} \]
\end{remark}

\subsection{Lagrangians for classical mechanics}

\begin{definition}
	In a system with kinetic energy $T(\underline{q}, \underline{\dot{q}})$ and potential energy $V(\underline{q})$, the Lagrangian that describes the equations of motion in that system is given by

	\[ L(\underline{q}, \underline{\dot{q}}) = T(\underline{q}, \underline{\dot{q}}) - V(\underline{q}) \]
\end{definition}

\subsection{Ignorable coordinates and conservation of generalised momenta}

\begin{definition}
	Let $\{ q_1, \dots, q_N \}$ be a set of generalised coordinates. A specific coordinates $q_i$ is \textbf{ignorable} if the Lagrangian function expressed in these generalised coordinates does not depend on $q_i$, i.e. if

	\[ \diffp{L}{q_i} = 0 \]
\end{definition}

\begin{definition}
	The \textbf{generalised momentum} $p_i$ associated with a generalised coordinate $q_i$ is given by

	\[ p_i := \diffp{L}{\dot{q_i}} \]
\end{definition}

\begin{proposition}\label{prop:generalisedIgnorableMomentumConserved}
	The generalised momentum associated to an ignorable coordinate is conserved.
\end{proposition}

\begin{proof}
	From the Euler-Lagrange equation for $q_i$,

	\[ 0 = \diff{}{t} \left( \diffp{L}{\dot{q_i}} \right) - \diffp{L}{q_i} = \diff{p_i}{t} - 0 = \diff{p_i}{t} \]
\end{proof}

\begin{example}
	For a free particle moving in $d$ dimensions, in Cartesian coordinates we have

	\[ L = T - V = \frac{1}{2} m \sum_{i = 1}^d \dot{x}_i^2 \]
	so every coordinate is ignorable. The generalised momenta are

	\[ p_i = \diffp{L}{\dot{x}_i} = m \dot{x}_i \]
	So here the conservation of generalised momenta is the conservation of the linear momenta.
\end{example}

\section{Symmetries, Noether's theorem and conservation laws}

\subsection{Ordinary symmetries}

\begin{definition}
	For a uniparametric family of smooth maps $\phi(\epsilon): C \rightarrow C$ from configuration space to itself, with $\phi(0)$ the identity map, this family of maps is called a \textbf{transformation depending on $\epsilon$}. In any coordinates system this transformation can be written as

	\[ q_i \rightarrow \phi_i(q_1, \dots, q_N, \epsilon) \]
	where the $\phi_i$'s are a set of $N := \dim(C)$ functions representing the transformation in the coordinate system. The change in velocities is defined as

	\[ \dot{q}_i \rightarrow \diff{}{t} \phi_i \]
\end{definition}

\begin{remark}
	$q_i'$ is used to denote $\phi(q_i, \epsilon)$, so often we write $q_i \rightarrow q_i' = \dots$, where $\dots$ is a function of $q_i$ and $\epsilon$.
\end{remark}

\begin{definition}
	The \textbf{generator} of $\phi$ is

	\[ \diff{\phi(\epsilon)}{\epsilon} \Big|_{\epsilon = 0} := \lim_{\epsilon \rightarrow 0} \frac{\phi(\epsilon) - \phi(0)}{\epsilon} \]
	In any coordinate system,

	\[ q_i \rightarrow \phi_i(\underline{q}, \epsilon) = q_i + \epsilon a_i(\underline{q}) + O(\epsilon^2) \]
	where

	\[ a_i = \diffp{\phi_i(\underline{q}, \epsilon)}{\epsilon} \Big|_{\epsilon = 0} \]
	is a function of the generalised coordinates. Hence the transformation generator is $a_i$. For the velocities the transformation is

	\[ \dot{q}_i \rightarrow \dot{q}_i + \epsilon a_i(q_1, \dots, q_N, \dot{q}_1, \dots, \dot{q}_N) + O(\epsilon^2) \]
	where the generator is $\dot{a}_i$.
\end{definition}

\begin{example}
	For a particle moving in two dimensions, the finite transformations given by rotations around the origin, in Cartesian coordinates, are
	\[
		\begin{aligned}
			& x \rightarrow x \cos(\epsilon) - y \sin(\epsilon) \\
			& y \rightarrow x \sin(\epsilon) + y \cos(\epsilon)
		\end{aligned}
	\]
	The associated infinitesimal transformations can be derived using the expansions $\sin(\epsilon) = \epsilon + O(\epsilon^3)$ and $\cos(\epsilon) = 1 + O(\epsilon^2)$. Then
	\[
		\begin{aligned}
			& x \rightarrow x - y \epsilon + O(\epsilon^2) \\
			& y \rightarrow y + x \epsilon + O(\epsilon^2)
		\end{aligned}
	\]
	Then the generators of the transformation are
	\[
		a_x = -y, \quad a_y = x, \quad \dot{a}_x = -\dot{y}, \quad \dot{a}_y = \dot{x}
	\]
\end{example}

\begin{lemma}
	Equations of motion do not change if the Lagrangian is modified by adding the total derivative of a function of coordinates and time, i.e.
	\[
		L \rightarrow L + \diff{F(q_1, \dots, q_N, t)}{t}
	\]
	results in the same equations of motion.
\end{lemma}

\begin{proof}
	The effect on the action is
	\[
		S = \int_{t_0}^{t_1} L dt \rightarrow S' = S + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)
	\]
	From the action principle, we must have that $\delta S$ vanishes to first order in $\delta q_i(t)$, with the $q_i$'s fixed at the path's endpoints. Therefore $F(q_1(t_1), \dots, q_N(t_1), t_1)$ and $F(q_1(t_0), \dots, q_N(t_0), t_0)$ are fixed. Hence
	\[
		\begin{aligned}
			\delta S' & = S'(\underline{q} + \delta \underline{q}) - S'(\underline{q}) \\
			& = (S(\underline{q} + \delta \underline{q}) + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)) \\
			& \quad - (S(\underline{q}) + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)) \\
			& = S(\underline{q} + \delta\underline{q}) - S(\underline{q}) = \delta S
		\end{aligned}
	\]
	So the variation of the action is not affected, therefore the equations of motion cannot be affected.
\end{proof}

\begin{definition}
	A transformation $\phi(\epsilon)$ is a \textbf{symmetry} if, to first order in $\epsilon$, for some function $F(\underline{q}, t)$, the change in the Lagrangian is a total time derivative of $F(\underline{q}, t)$, i.e.

	\[
		L \rightarrow L + \epsilon \diff{F(\underline{q}, t)}{t} + O(\epsilon^2)
	\]
\end{definition}

\begin{remark}
	$F(\underline{q}, t)$ is only defined up to a constant. If some $F(\underline{q}, t)$ satisfies the above equation, then $G(\underline{q}, t) = F(\underline{q}, t) + c$ will also satisfy the equation.
\end{remark}

\begin{example}
	If $q_i$ is an ignorable coordinate, the transformation $q_i \rightarrow q_i + c_i$, where $c_i$ is a constant, is a symmetry, because $q_i$ does not appear in the Lagrangian by definition so here $F(\underline{q}, t) = 0$.
\end{example}

\begin{theorem}
	(Noether's theorem) In a given set of generalised coordinates, let $a_i(\underline{q})$ be the generator of a transformation such that
	\[
		L \rightarrow L + \epsilon \diff{F(\underline{q}, t)}{t} + O(\epsilon^2)
	\]
	so that it is a symmetry. Let
	\[
		Q := \left( \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right) - F
	\]
	Then $\diff{Q}{t} = 0$, so $Q$ is conserved. $Q$ is called the \textbf{Noether charge}.
\end{theorem}

\begin{proof}
	Consider the variation of the action under the transformation $q_i \rightarrow q_i + \epsilon a_i$. Using the chain rule and then the Euler-Lagrange equations,
	\[
		\begin{aligned}
			\delta S
				& = \int_{t_0}^{t_1} \sum{i = 1}^N \left( \epsilon a_i \diffp{L}{q_i} + \epsilon \dot{a}_i \diffp{L}{\dot{q}_i} \right) dt + O(\epsilon^2) \\
				& = \int_{t_0}^{t_1} \sum_{i = 1}^N \left( \epsilon a_i \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) + \epsilon \dot{a}_i \diffp{L}{\dot{q}_i} \right) + O(\epsilon^2) \\
				& = \int_{t_0}^{t_1} \epsilon \diff{}{t} \left( \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right) + O(\epsilon^2) \\
				& = \epsilon {\left[ \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right]}_{t_0}^{t_1} + O(\epsilon^2)
		\end{aligned}
	\]
	Note that having used the Euler-Lagrange equations in the second line, the result is only valid along the path satisfying the equations of motion.

	Now since the transformation is a symmetry,
	\[
		\begin{aligned}
			\delta S
				& = S(\underline{q} + \delta \underline{q}) - S(\underline{q}) \\
				& = \int_{t_0}^{t_1} \left( \left( L + \epsilon \diff{F}{t} + O(\epsilon^2) \right) - L \right) \\
				& = \epsilon {[F]}_{t_0}^{t_1} + O(\epsilon^2)
		\end{aligned}
	\]
	Equating these two expressions for $\delta S$, we see that $Q(t_1) = Q(t_0)$. We didn't specify what $t_0$ and $t_1$ were so this equality holds for every $t_0$ and $t_1$. So let $t_1 = t_0 + \epsilon$, then
	\[
		Q(t_1) - Q(t_0) = Q(t_0 + \epsilon) - Q(t_0) = \epsilon \diff{Q}{t} + O(\epsilon^2) = 0
	\]
	hence $\diff{Q}{t} = 0$.
\end{proof}

\begin{example}
	If a coordinate $q_i$ is ignorable, there is a symmetry generated by $q_i \rightarrow q_i + \epsilon$ and leaving the other coordinates constant. So
	\[
		a_k = \delta_{ik} := \begin{cases}
			1 & \quad \text{if } i = k \\
			0 & \quad \text{otherwise}
		\end{cases}
	\]
	The Noether charge is
	\[
		Q = \sum_{k = 1}^{N} a_k \diffp{L}{\dot{q}_k} = \sum_{k = 1}^{N} \delta_{ik} \diffp{L}{\dot{q}_k} = \diffp{L}{\dot{q}_i}
	\]
	which agrees with Proposition \ref{prop:generalisedIgnorableMomentumConserved}.
\end{example}

\subsection{Energy conservation}

\begin{definition}
	Given a Lagrangian that explicitly depends on time, $L(\underline{q}, \underline{\dot{q}}, t)$, the \textbf{energy}, $E$, is defined as
	\[
		E := \left( \sum_{i = 1}^{N} \dot{q}_i \diffp{L}{\dot{q}_i} \right) - L
	\]
\end{definition}

\begin{theorem}
	Along a path $\underline{q}(t)$ which satisfies the equations of motion,
	\[
		\diff{E}{t} = -\diffp{L}{t}
	\]
\end{theorem}

\begin{proof}
	\[
		\begin{aligned}
			\diff{E}{t}
				& = \diff{}{t} \left( \left( \sum_{i = 1}^{N} \dot{q}_i \diffp{L}{\dot{q}_i} \right) - L \right) \\
				& = \sum_{i = 1}^{N} \left( \ddot{q}_i \diffp{L}{\dot{q}_i} + \dot{q}_i \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) \right) - \diff{L}{t} \\
				& = \sum_{i = 1}^{N} \left( \diffp{L}{\dot{q}_i} \ddot{q}_i + \dot{q}_i \diffp{L}{q_i} \right) - \diff{L}{t}
		\end{aligned}
	\]
	using the Euler-Lagrange equations. By the chain rule,
	\[
		\diff{L}{t} = \sum_{i = 1}^{N} \left( \diffp{L}{\dot{q}_i} + \diffp{L}{q_i} \dot{q}_i \right) + \diffp{L}{t}
	\]
	and so substituting this into the expression for $\diff{E}{t}$, we get
	\[
		\diff{E}{t} = -\diffp{L}{t}
	\]
\end{proof}

\begin{remark}
	Note that $\diffp{L}{t}$ means the partial derivative of $L$ with respect to $t$, \textbf{keeping $\underline{q}$ and $\underline{\dot{q}}$ fixed}. This is because the Lagrangian is (here) just an ordinary function of three parameters which are unrelated, so $t$ is independent of $\underline{q}$ and $\underline{\dot{q}}$. The parameters only become related when the Lagrangian is used to build the action. (See \hyperref[rem:lagrangianParametersIndependent]{this remark}).
\end{remark}

\begin{corollary}
	Energy is conserved iff the Lagrangian does not depend explicitly on time.
\end{corollary}

\begin{proof}
	Energy is conserved iff $\diff{E}{t} = 0$, and $\diffp{L}{t} = 0$ iff the Lagrangian does not depend explicitly on time.
\end{proof}

\section{Normal modes}

\subsection{Canonical kinetic terms}

\begin{definition}
	Given a Lagrangian $L = T - V$, $T$ is a \textbf{canonical} kinetic term if it is of the form
	\[
		T = \frac{1}{2} \sum_{i = 1}^{n} \dot{q}_i^2
	\]
\end{definition}

Given a Lagrangian with a canonical kinetic term, assume $\underline{q} = \underline{0}$ is a stationary point of $V(\underline{q})$, so
\[
	\diffp{V}{q_i} \Big|_{\underline{q} = 0} = 0 \quad \forall i \in \{ 1, \dots, n \}
\]

If $\underline{q} = \underline{0}$ is not a stationary point but $\underline{q} = \underline{a}$ for some $\underline{a}$ is, then the new variables defined as $q_i' = q_i - a_i$ are such that the stationary point is at $\underline{q}' = \underline{0}$. This preserves the form of the Lagrangian, so we can assume $\underline{q} = 0$ is a stationary point.

To determine the motion around this extremum, expand $V(\underline{q})$ to second order in $\underline{q}$ to define an approximate Lagrangian:
\[
	L_{\text{approx}} = \frac{1}{2} \sum_{i = 1}^{n} \dot{q}_i^2 - \frac{1}{2} \sum_{i, j} A_{i, j} q_i q_j
\]
where
\[
	A_{i, j} = \diffp[1, 1]V{q_i, q_j} \Big|_{\underline{q} = 0}
\]
The Euler-Lagrange equations for $L_{\text{approx}}$ are given in matrix notation by
\[
	\underline{\ddot{q}} + A \underline{q} = D_A \underline{q} = \left( \diff[2]{}{t} + A \right) \underline{q} = 0
\]
where $D_A$ is defined as $D_A := \diff[2]{}{t} + A$, which is a linear operator ($D_A (\underline{a} + \underline{b}) = D_A \underline{a} + D_A \underline{b}$ and $D_A (c \underline{a}) = c D_A \underline{a}$ for any vectors $a$ and $b$ and any $c \in \mathbb{R}$).

$A$ is an $n \times n$ matrix which is real and symmetric, due to symmetry of second partial derivatives (we assume $V$ has continuous second partial derivatives). So $A$ has $n$ real eigenvaules and eigenvectors. Let the eigenvalues be $\lambda^{(i)}$ and the corresponding eigenvectors be $\underline{v}^{(i)}$, then
\[
	A \underline{v}^{(i)} = \lambda^{(i)} \underline{v}^{(i)}
\]
Define the ansatz (an assumed solution)
\[
	\underline{q}^{(i)} (t) = f^{(i)} (t) \underline{v}^{(i)}
\]
for some function $f^{(i)} (t)$ to be determined. Then
\[
	\begin{aligned}
		\left( \diff[2]{}{t} + A \right) \underline{q}^{(i)} (t)
			& = \left( \diff[2]{}{t} + A \right) f^{(i)} (t) \underline{v}^{(i)}
			& = \underline{v}^{(i)} \left( \diff[2]{}{t} + \lambda^{(i)} \right) f^{(i)} (t)
			& = 0
	\end{aligned}
\]
and so since $\underline{v}^{(i)} \ne 0$,
\[
	\left( \diff[2]{}{t} + \lambda^{(i)} \right) f^{(i)} (t) = 0
\]
The solution to this equation is
\[
	f^{(i)} (t) = \begin{cases}
		\alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) & \quad \text{if } \lambda^{(i)} > 0 \\
		C^{(i)} t + D^{(i)} & \quad \text{if } \lambda^{(i)} = 0 \\
		\alpha^{(i)} \cosh(\sqrt{-\lambda^{(i)}} t) + \beta^{(i)} \sinh(\sqrt{-\lambda^{(i)}} t) & \quad \text{if } \lambda^{(i)} < 0 \\
	\end{cases}
\]
where $\alpha^{(i)}, \beta^{(i)}, C^{(i)}, D^{(i)}$ are constants determined by initial conditions.

The behaviour this solution describes depends on the sign of the $\lambda^{(i)}$. If every $\lambda^{(i)}$ is positive, there is a local minimum and there are oscillations around this minimum. If there is a negative eigenvalue, there is exponential behaviour away from the stationary point, which matches with the intuitioin that small perturbations at a maximum will quickly grow. Zero eignvaleues correspond with motion with constant velocity, with no oscillations.

The general solution is
\[
	\underline{q}(t) = \sum_{i = 1}^{N} \underline{v}^{(i)} f^{(i)} (t)
\]

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} > 0$, a \textbf{normal mode} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( \alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) \right)
	\]
\end{definition}

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} = 0$, a \textbf{zero mode} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( C^{(i)} t + D^{(i)} \right)
	\]
\end{definition}

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} < 0$, an \textbf{instability} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( \alpha^{(i)} \cosh(\sqrt{-\lambda^{(i)}} t) + \beta^{(i)} \sinh(\sqrt{-\lambda^{(i)}} t) \right)
	\]
\end{definition}

\begin{definition}
	When there are no instabilities, the general solution is the superposition of normal modes for non-zero eigenvalues and zero modes:
	\[
		\underline{q}(t) = \sum_{i = 1, \ \lambda^{(i)} \ne 0}^{n} \underline{v}^{(i)} \left( \alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) \right) + \sum_{i = 1, \ \lambda^{(i)} = 0}^{n} \underline{v}^{(i)} \left( C^{(i)} t + D^{(i)} \right)
	\]
\end{definition}

\begin{remark}
	If the starting potential $V(\underline{q})$ is deformed slightly, then the zero eigenvalues of $A$ will become positive or negative. So if a system has a zero mode, we expect to find a principle that restricts the deformations of $V(\underline{q})$.

	For example, consider two particles of the same mass in one dimension, with positions $x_1$ and $x_2$. Say we have a symmetry
	\[
		\begin{aligned}
			x_1 \to x_1 + \epsilon a \\
			x_2 \to x_2 + \epsilon a
		\end{aligned}
	\]
	for a constant $a$. Then the potential only depends on the difference $x_1 - x_2$ and we have
	\[
		L = \frac{1}{2} m (\dot{x}_1^2 + \dot{x}_2^2) - V(x_1 - x_2)
	\]
	This symmetry gives rise to a zero mod associated with translation of the system's centre of mass. To see this, define new coordinates $x_+ = \frac{1}{\sqrt{2}} (x_1 + x_2)$ and $x_- = \frac{1}{\sqrt{2}} (x_1 - x_2)$. Then the Lagrangian is given by
	\[
		L = \frac{1}{2} m (\dot{x}_+^2 + \dot{x}_-^2) - V(\sqrt{2} x_-)
	\]
	which has a zero mod for $x_+$. So zero modes still exist under translation symmetry.
\end{remark}

\begin{example}
	Consider two pendula, of length $1$ with mass $1$, suspended a distance $d$ apart. The masses on the pendula are connected by a spring with constant $k$ and natural length $d$. Let $\theta_1$ be the angle between the first pendulum and the vertical, and $\theta_2$ be the angle between the second pendulum and the vertical. The velocity of the first mass is $(-\cos(\theta_1) \dot{\theta}_1)^2 + (\sin(\theta_1) \dot{q}_1)^2 = \dot{\theta}_1^2$, and similarly the velocity of the second mass is $\dot{\theta}_2^2$. The kinetic energy is therefore
	\[
		T = \frac{1}{2} (\dot{\theta}_1^2 + \dot{\theta}_2^2)
	\]
	The potential from gravity is $-g(\cos(\theta_1) + \cos(\theta_2))$ and the potential from the spring is $k(l - d)^2 / 2$, where $l - d$ is the extension and
	\[
		l = \sqrt{(\cos(\theta_1) - \cos(\theta_2))^2 + (\sin(\theta_1) - \sin(\theta_2) + d)^2}
	\]
	
\end{example}

NOTES directly from lecture notes up to here.

\section{Hamiltonian Formalism}

\begin{definition}
	The classical \textbf{state} of a system at a given instant in time is a \textbf{complete} set of data that fully specifies the future evolution of the system.
\end{definition}

\begin{remark}
	\textbf{Any} set of data that fully fixes future evolution is valid.
\end{remark}

\begin{definition}
	The \textbf{phase (or state) space} is the set of all possible states for a system at a given time.
\end{definition}

\begin{example}
	A free particle moving in $\mathbb{R}$. The phase space is $\mathbb{R}^2$ ($\mathbb{R}$ for position, $\mathbb{R}$ for velocity).
\end{example}

\begin{definition}
	The \textbf{Hamiltonian formalism} studies dynamics in a phase space, parameterised by $\underline{q}(t)$ and $\underline{p}(t)$, where $p_i = \diffp{L}{\dot{\underline{q_i}}}$, the momentum.
\end{definition}

\begin{example}
	A particle moving in $\mathbb{R}$, with $L(x, \dot{x}) = \frac{1}{2} m \dot{x}^2$.

	Then $p_x = \diffp{L}{\dot{x}} = m \dot{x}$ so $\dot{x}(x, p_x) = \frac{p_x}{m}$.

	In the Hamltonian formalism, $L(x, p_x) = \frac{p_x^2}{2m}$.
\end{example}

\begin{example}
	A particle moving in $\mathbb{R}^2$ (in polar coordinates).

	$L(r, \theta, \dot{r}, \dot{\theta}) = \frac{1}{2} m (\dot{r}^2 + r^2 \dot{\theta}^2)$. So $p_r = m\dot{r}$ and $p_{\theta} = m r^2 \dot{\theta}$.

	So $\dot{r}(r, \theta, p_r, p_{\theta}) = \frac{p_r}{m}$, $\dot{\theta}(r, \theta, p_r, p_{\theta}) = \frac{p_{\theta}}{m r^2}$.

	$L(r, \theta, \dot{r}, \dot{\theta}) = L(r, \theta, p_r, p_{\theta}) = \frac{1}{2} (\frac{p_r^2}{m} + \frac{p_{\theta}^2}{m r^2})$.
\end{example}

\begin{definition}
	Given two functions $f(\underline{q}, \underline{p}, t)$ and $g(\underline{q}, \underline{p}, t)$ in phase space their \textbf{Poisson bracket} is:

	\[ \{f, g\} := \sum_{i = 1}^n \left( \diffp{f}{q_i} \diffp{g}{p_i} - \diffp{f}{p_i} \diffp{g}{q_i} \right)\] where $n$ is the dimension of the configuration space.
\end{definition}

\begin{remark}
	In the Hamiltonian formalism, $\diffp{q_i}{p_j} = \diffp{p_j}{q_i} = 0$.

	Similarly, $\diffp{q_i}{q_j} = \diffp{p_i}{p_j} = \delta_{i, j}$
\end{remark}

\begin{example}
	Let $f = q_i$, $g = q_j$. $\{q_i, q_j\} = 0$, and $\{p_i, p_j\} = 0$. $\{q_i, p_j\} = \sum_{k = 1}^n \delta_{i, j} \delta_{j, k} = \delta_{i, j}$.
\end{example}

\begin{definition}
	Let $\mathbb{F}$ be the set functions from a phase space $P$ to $\mathbb{R}$
\end{definition}

\begin{definition}
	The Hamiltonian flow $\Phi_f^{(s)}$, with $(s) \in \mathbb{R}$, $f \in F$ operator maps $\mathbb{F}$ to $\mathbb{F}$ and is defined as

	\[ \Phi_f^{(s)} (g) := e^{s \{\cdot, f\}} g := g + s \{g, f\} + \frac{s^2}{2} \{ \{g, f\}, f\} + \cdots \]
\end{definition}

\begin{remark}
	The transformation generated by $f$ has generator $a_i = \{q_i, f\}$ where $q_i \rightarrow q_i + \epsilon a_i$.

	Infinitesimally, $\Phi_f^{(s)} (g) := g + \epsilon \{g, f\} + O(\epsilon^2)$
\end{remark}

TODO: properties on poisson bracket

\begin{example}
	(Rotation in $\mathbb{R}^2$ in Cartesian coordinates) As a guess, choose $f = q_1 \dot{q_2} - \dot{q_1} q_2$, the angular momentum.

	$L = \frac{1}{2} (\dot{q_1}^2 + \dot{q_2}^2) - V(q_1, q_2)$ so $p_1 = \diffp{L}{\dot{q_1}} = \dot{q_1}$ and $p_2 = \diffp{L}{\dot{q_2}} = \dot{q_2} \Rightarrow f = q_1 p_2 - q_2 p_1$.

	Then $q_1 \rightarrow q_1 + \epsilon \{ q_1, f \} + O(\epsilon^2) = q_1 + \epsilon \{ q_1, q_1 p_2 - q_2 p_1 \} = q_1 + \epsilon \{ q_1, q_1 p_2 \} - \epsilon \{ q_1, q_2 p_1 \} = q_1 + \epsilon \{q_1, q_1\} p_2 + \epsilon \{q_1, p_2\} q_1 - \epsilon \{q_1, q_2\} p_1 - \epsilon \{q_1, p_1\} q_2 = q_1 - \epsilon q_2$

	Similarly, $q_2 \rightarrow q_2 + \epsilon q_1$ so $(q_1, q_2) \rightarrow (q_1, q_2) + \epsilon ((0, -1), (1, 0)) (q_1, q_2)$ TODO make into matrices and column vectors.
\end{example}

\begin{definition}
	The \textbf{Hamiltonian} is the energy expressed in Hamiltonian coordinates:

	\[ H = \sum_{i = 1}^n \dot{q_i(\underline{q}, \underline{p})} p_i - L(\underline{q}, \dot{\underline{q}} (\underline{q}, \underline{p})) \]
\end{definition}

\begin{example}
	(Harmonic oscillator in one dimension) Let $\frac{1}{2} m \dot{x}^2 - \frac{1}{2} k x^2 \Rightarrow p = m\dot{x} \Rightarrow \dot{x} = \frac{p}{m}$.

	$H = \dot{x} p - L = \frac{p^2}{m} - (\frac{1}{2} \frac{p^2}{m} - \frac{1}{2} k x^2) = \frac{1}{2} \frac{p^2}{m} + \frac{1}{2} k x^2$
\end{example}

\begin{theorem}
	The time evolution of the phase space coordinates $\underline{q}, \underline{p}$ is generated by Hamiltonian flow $\Phi_H$:

	\[ q_i(t + a) = \Phi_H^{(a)} q_i(t), p_i(t + a) = \Phi_H^{(a)} p_i(t) \]
	Infinitesimally, $q_i(t) + \epsilon \dot{q_i}(t) + O(\epsilon^2) = q_i(t + \epsilon) = q_i(t) + \epsilon \{ q_i, H \} + O(\epsilon^2) \Leftrightarrow \dot{q_i} = \{q_i, H \} = \diffp{H}{p_i}$ and similarly, $\dot{p_i} = \{ p_i, H \} = -\diffp{H}{q_i}$.
	
	These equations are called \textbf{Hamilton's equations}.
\end{theorem}

\begin{proof}
	$\diffp{H}{q_i}$. TODO: complete this proof, finish rest of notes from lecture.
\end{proof}

\begin{corollary}
	The time evolution of any function $f(\underline{q}, \underline{p})$ in phase space is generated by $\Phi_H$:

	\[ \diff{f}{t} = \{ f, H \} \]
	If $f(\underline{q}, \underline{p}, t)$ depends explicitly on time then

	\[ \diff{f}{t} = \{ f, h \} + \diffp{f}{t} \]
\end{corollary}

\begin{proof}
	$\diff{f}{t} = \sum_{i = 1}^n \left( \diffp{f}{q_i} \dot{q_i} + \diffp{f}{p_i} \dot{p_i} \right) + \diffp{f}{t} = \sum_{i = 1}^n \left( \diffp{f}{q_i} \diffp{H}{p_i} - \diffp{f}{p_i} \diffp{H}{q_i} \right) + \diffp{f}{t} = \{ f, H \} + \diffp{f}{t}$.
\end{proof}

\section{Quantum mechanics introduction}

\begin{definition}
	The \textbf{photo-electric effect} is the phenomena where, when a light source is shone on a metal, electrons are released from the surface of the metal.
\end{definition}

\begin{definition}
	The \textbf{classical} description of light would lead to these results:
	\begin{itemize}
		\item The energy of the released electrons depends on the intensity of light $I$ but is independent of the angular frequency of the light, $\omega$.
		\item Electrons are released for any value of $I$
	\end{itemize}
\end{definition}

\begin{definition}
	The quantum mechanics prediction of the photoelectric effect is that the energy of the electrons $E$ is independent of $I$, and not released at all below some value of angular frequency.

	This led to the discovery that light consists of packets (photons).
\end{definition}

\section{The wave function and probabilities}

\begin{definition}
	The \textbf{wave function} is a function of position $x$ and time $t$:
	\[
		\psi: \mathbb{R}^2 \rightarrow \mathbb{C}
	\]
	Often we will refer to a wave function as $\psi(x)$, a function of just position, at a fixed point in time.
\end{definition}

\begin{remark}
	We require that $\psi$ is continuous, and that $\diffp{\psi(x)}{x}$ is continuous ($\psi$ must be differentiable), except when the potential energy $V(x)$ is not finite. 
\end{remark}

\begin{definition}
	The \textbf{probability density} of finding a particle at position $x$ and time $t$ is defined as
	\[
		P(x, t) := |\psi(x, t)|^2
	\]

	The probability of finding the particle at $x \in [a, b]$ is therefore
	\[
		\int_a^b |\psi(x, t)|^2 dx
	\]
	The probability of finding the particle anywhere is must be equal to $1$, which means that
	\[
		\int_{-\infty}^{\infty} P(x, t) dx = 1 \quad \forall t \in \mathbb{R}
	\]
	This puts a constraint on $\psi$.
\end{definition}

\begin{definition}
	A wave function $\psi$ is called \textbf{square-normalisable} if the integral
	\[
		\int_{-\infty}^{\infty} P(x, t) dx
	\]
	exists.
\end{definition}

\begin{definition}
	A wave function $\psi$ is called \textbf{normalised} if
	\[
		\int_{-\infty}^{\infty} P(x, t) dx = 1 \quad \forall t \in \mathbb{R}	
	\]
\end{definition}

\begin{definition}
	For a given time $t$, the \textbf{expectation} value of a polynomial function $f(x)$ of position $x$, is defined as
	\[
		\langle f(x) \rangle := \int_{-\infty}^{\infty} P(x, t) f(x) dx
	\]
\end{definition}

\begin{remark}
	The expectation of position, $\langle x \rangle$ is the mean of measurements of the positions of many particles with wave function $\psi$.
\end{remark}

\begin{definition}
	The \textbf{uncertainty} of a quantity $A$ is defined as
	\[
		\Delta A = \sqrt{\langle A^2 \rangle - \langle A \rangle ^2}
	\]
\end{definition}

\subsection{Examples of wave functions}

\begin{definition}
	The \textbf{Gaussian wave function} is defined as
	\[
		\psi(x) = C e^{-x^2 / 4 \Delta^2}
	\]
	where $\Delta > 0$ has units of length and $C$ is a normalisation constant.
	\[
		\int_{-\infty}^{\infty} |\psi(x)|^2 = 1
	\]
	so $C = e^{i \theta} {(2 \pi \Delta^2)}^{-1/4}$, with $\theta \in \mathbb{R}$. $\theta$ is a free parameter here, so is often set to $0$.

	So the normalised probability distribution is
	\[
		P(x) = \frac{1}{\sqrt{2 \pi \Delta^2}} e^{-x^2 / (2 \Delta^2)}
	\]
	which is a standard Gaussian probability distribution.
\end{definition}

\begin{remark}
	For the Gaussian wave function:
	\begin{itemize}
		\item $\langle x^{2n + 1} \rangle \ \forall n \in \mathbb{N}_0$ since the integral is an odd function of $x$ over a symmetric interval.
		\item As $\Delta$ is the only quantity with units of length and $x$ has units of length, $\langle x^{2n} \rangle \propto \Delta^{2n} \ \forall n \in \mathbb{N}_0$.
		\item $\langle x^2 \rangle = \Delta^2 \Longrightarrow \Delta x = \Delta$.
	\end{itemize}
\end{remark}

\begin{definition}
	If a particle's position $x$ is confined to $0 < x < L$, particle is said to be in an \textbf{infinite potential well}, with the potential of the particle defined as
	\[
		V(x) = \begin{cases}
			0 & \text{ if } 0 < x < L \\
			\infty & \text{ otherwise}
		\end{cases}
	\]
	To have position $x \le 0$ or $x \ge L$, the particle would need infinite energy, so the probability of finding it there is $0$, therefore the wave function for the particle should vanish in these regions.
\end{definition}

\begin{example}
	A possible wave function for a particle in an infinite potential well is
	\[
		\Psi(x) = \begin{cases}
			C \sqrt{x(L - x)} & \text{ if } 0 < x < L \\
			0 & \text{ otherwise }
		\end{cases}
	\]
	For some constant $C$. The probability of finding the particle anywhere in $(0, L)$ is $1$, so
	\[
		\int_{0}^{L} |\psi(x)|^2 dx = |C|^2 \int_{0}^{L} x(L - x) dx = |C|^2 \frac{L^3}{6} = 1
	\]
	which implies $C = \sqrt{6 / L^3} e^{i \theta}$ for any $\theta$. We often choose $\theta = 0$ for simplicity.
\end{example}

\begin{remark}
	\textbf{Important:} multiplying a wave function $\psi(x)$ by $e^{i \theta}$ for any $\theta \in \mathbb{R}$ does not change the probability density function $P$, which means that measuring position cannot distinguish between $\psi(x)$ and $e^{i \theta} \psi(x)$.
	
	Measuring momentum can distinguish between these two, unless $\theta(x)$ is constant, in which case they cannot be distinguished by any measurement, and they describe the same physical state.
\end{remark}

\subsection{Collapse of the wave function}

\begin{definition}
	If a particle has a wave function $\psi(x, t)$ for $t < t_0$, then at $t = t_0$, the position $x$ is measured to be $x = x_0$. Then another measurement immediately after the first will be $x = x_0$ with probability $1$. This phenomenon is called the \textbf{wave function collapse}. Measuring $x$ changes the wave function so that it is very localised around $x_0$. This is why $\langle x \rangle$ is the average of measurements of many particles with the same wave function, not repeated measurements of the same wave function.
\end{definition}

\section{Momentum and Planck's constant}

\begin{definition}
	The \textbf{momentum operator} $\hat{p}$ is defined as
	\[
		\hat{p} \psi(x) := -i \hbar \diffp{}{x} (\psi(x))
	\]
	so that
	\[
		\begin{aligned}
			\delta_{\epsilon} \psi(x)
				& := \psi(x - \epsilon) - \psi(x) \\
				& = -\epsilon \diffp{}{x} \psi(x) + O(\epsilon^2) \\
				& = -\epsilon \frac{i}{\hbar} \hat{p} \psi(x)
		\end{aligned}
	\]
	where $\hbar$ is a constant of proportionality.
\end{definition}

\begin{definition}
	In the above definition, $\hbar$ is called the \textbf{reduced Planck constant} which has units $\text{energy} \times \text{time}$. \textbf{Planck's constant} is defined as
	\[
		h = 2 \pi \hbar
	\]
\end{definition}

\begin{definition}
	The \textbf{position operator} $\hat{x}$, which multiplies a wave function by $x$, is defined as
	\[
		\hat{x} \psi(x) = x \psi(x)
	\]
\end{definition}

\begin{definition}
	The \textbf{commutator} of the position and momentum operators $\hat{x}$ and $\hat{p}$ is defined as
	\[
		\begin{aligned}
			\relax [\hat{x}, \hat{p}] \psi(x)
				& = \hat{x} (\hat{p} (\psi(x))) - \hat{p} (\hat{x} (\psi(x))) \\
				& = \hat{x} \left( -i \hbar \diffp{}{x} \psi(x) \right)	+ i \hbar \diffp{}{x} (x \psi(x)) \\
				& = i \hbar \psi(x)
		\end{aligned}
	\]
	The relation $[\hat{x}, \hat{p}] (\psi(x)) = i \hbar \psi(x)$ is called the \textbf{canonical commutation relation}.
\end{definition}

\begin{remark}
	This commutator is similar to the Poisson bracket, where $\{ x, p \} = 1$ in classical mechanics. So we can transform a classical system into a quantum system by replacing the Poisson bracket $\{ , \}$ with $-\frac{i}{\hbar} [,]$. This replacement is called \textbf{canonical quantisation}.
\end{remark}

\begin{definition}
	The \textbf{expectation value of momentum}, $\langle p \rangle$ is defined as
	\[
		\begin{aligned}
			\langle p \rangle
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} \hat{p} (\psi(x, t)) dx \\
				& = -i \hbar \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx
		\end{aligned}
	\]
\end{definition}

\begin{remark}
	Notice the similarity between this definition and the one for the expectation value of position:
	\[
		\begin{aligned}
			\langle x \rangle
				& = \int_{-\infty}^{\infty} x |\psi(x, t)|^2 dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} \hat{x} (\psi(x, t)) dx
		\end{aligned}
	\]
	As with $\langle x \rangle$, $\langle p \rangle$ is interpreted as the average of measurements of the momenta of many particles with the same wave function $\psi$.
\end{remark}

\begin{proposition}
	$\hbar$ must be a real number (it is not complex).
\end{proposition}

\begin{proof}
	The measurement of momentum must be a real number, so $\langle p \rangle \in \mathbb{R}$. Using integration by parts and the fact that $|\psi(x, t)|^2$ vanishes as $x \rightarrow \pm \infty$ if $\psi$ is square normalisalbe, the complex conjuate of $\langle p \rangle$ is
	\[
		\begin{aligned}
			\overline{\langle p \rangle}
				& = i \bar{\hbar} \int_{-\infty}^{\infty} \psi(x, t) \diffp{}{x} \overline{\psi(x, t)} dx \\
				& = -i \bar{\hbar} \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx + i \hbar {[|\psi(x, t)|^2]}_{-\infty}^{\infty} \\
				& = -i \bar{\hbar} \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx \\
				& = \frac{\bar{\hbar}}{\hbar} \langle p \rangle
		\end{aligned}
	\]
	Therefore $\langle p \rangle \in \mathbb{R} \Longleftrightarrow \hbar \in \mathbb{R}$, so $\hbar$ must be real.
\end{proof}

\begin{definition}
	The \textbf{expectation value} of any polynomial $f$ of $p$ can be calculated as
	\[
		\begin{aligned}
			\langle f(p) \rangle
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} f(\hat{p}) \psi(x, t) dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} f \left( -i \hbar \diffp{}{x} \right ) (\psi(x, t)) dx
		\end{aligned}
	\]
\end{definition}

\begin{definition}
	The \textbf{momentum uncertainty}, $\Delta p$ is defined as
	\[
		\Delta p = \sqrt{\langle p^2 \rangle - {\langle p \rangle}^2}
	\]
	This quantity describes the spread around $\langle p \rangle$ of measurements of the momenta of many particles with the same wave function $\psi$.
\end{definition}

\begin{example}
	For the Gaussian wave function, $\langle x \rangle = 0$ and $\langle x^2 \rangle = \Delta^2$ so the uncertainty in position is $\Delta x = \Delta$. The momentum operator applied to $\psi$ gives
	\[
		\begin{aligned}
			\hat{p} (\psi(x)) & = \frac{i \hbar}{2 \Delta^2} x \psi(x) \\
			\hat{p}^2 (\psi(x))
				& = -\hbar^2 \diffd[2]{}{x} (\psi(x)) \\
				& = \frac{\hbar^2}{2 \Delta^2} \psi(x) - \frac{\hbar^2}{4 \Delta^4} x^2 \psi(x)
		\end{aligned}
	\]
	Notice that the momentum operator always gives a polynomial in $x$ multiplied by $\psi(x)$, so we can use the position expectations to calculate the momentum expectations:
	\[
		\begin{aligned}
			\langle p \rangle & = \frac{i \hbar}{2 \Delta^2} \int_{-\infty}^{\infty} x |\psi(x)|^2 dx = \frac{i \hbar}{2 \Delta^2} \langle x \rangle = 0 \\
			\langle p^2 \rangle
				& = \frac{\hbar^2}{2 \Delta^2} \int_{-\infty}^{\infty} |\psi(x)|^2 dx - \frac{\hbar^2}{4 \Delta^4} \int_{-\infty}^{\infty} x^2 |\psi(x)|^2 dx \\
				& = \frac{\hbar^2}{2 \Delta^2} - \frac{\hbar^2}{4 \Delta^4} \langle x^2 \rangle \\
				& = \frac{\hbar^2}{2 \Delta^2} - \frac{\hbar^2}{4 \Delta^4} \Delta^2 \\
				& = \frac{\hbar^2}{4 \Delta^2}
		\end{aligned}
	\]
	So the uncertainty in momentum is
	\[
		\Delta p = \sqrt{\langle p^2 \rangle - {\langle p \rangle}^2} = \frac{\hbar}{2 \Delta}
	\]
	So the product of the uncertainties of position and momentum is a constant, independent of $\Delta$:
	\[
		\Delta x \Delta p = \frac{\hbar}{2}
	\]
	So as the uncertainty in position or momentum decreases, the other must increase.
\end{example}

\begin{definition}
	\textbf{Heisenberg's uncertainty principle} states that for every normalised wave function,
	\[
		\Delta x \Delta p \ge \frac{\hbar}{2}
	\]
\end{definition}

\begin{remark}
	Heisenberg's uncertainty principle shows that there is a limit on the how much the uncertainty in both position and momentum can be reduced.
\end{remark}

\begin{definition}
	A \textbf{minimal uncertainty wave function} is a wave function that minimises the quantity $\Delta x \Delta p$, i.e. $\Delta x \Delta p = \frac{\hbar}{2}$.
	
	The Gaussian wave function is an example of this.
\end{definition}

\subsection{The Hilbert space}

\begin{definition}
	A \textbf{Hermitian inner product} on a vector space $V$ is a map $\langle \cdot, \cdot \rangle: V \times V \rightarrow \mathbb{C}$ which satisifes the following properties:
	\begin{enumerate}
		\item $\forall v, w \in V, \langle v, w \rangle = \overline{\langle w, v \rangle}$.
		\item $\forall v, w_1, w_2 \in V, a_1, a_2 \in \mathbb{C}, \langle v, a_1 w_1 + a_2 w_2 \rangle = a_1 \langle v, w_1 \rangle + a_2 \langle v, w_2 \rangle$.
		\item $\forall v, w_1, w_2 \in V, a_1, a_2 \in \mathbb{C}, \langle a_1 w_1 + a_2 w_2, v \rangle = \overline{a_1} \langle w_1, v \rangle + \overline{a_2} \langle w_2, v \rangle$.
		\item $\forall v \in V, \langle v, v \rangle \ge 0$ and $\langle v, v \rangle = 0 \Longleftrightarrow v = 0$.
	\end{enumerate}
\end{definition}

\begin{remark}
	A basis $\{ e_j \}$ is an orthonormal basis for an $n$-dimensional vector space $V$ if
	\[
		\langle e_i, e_j \rangle = \delta_{i, j}
	\]
	This means for every $v \in V$,
	\[
		v = \sum_{i = 1}^{n} v_i e_i
	\]
	where the $i$th component of the vector is $v_i = \langle v, e_i \rangle$. The Hermitian inner product of $v, w \in V$ is therefore
	\[
		\langle v, w \rangle = \sum_{i = 1}^{n} \overline{v_i} w_i
	\]
\end{remark}

\begin{definition}
	The \textbf{norm} of a vector $v \in V$ is defined as
	\[
		|v| := \sqrt{\langle v, v \rangle}
	\]
\end{definition}

\begin{remark}
	With an orthonormal basis, the squared norm of $v$ is simply
	\[
		|v|^2 := \langle v, v \rangle = \sum_{i = 1}^{n} |v_i|^2
	\]
\end{remark}

\begin{definition}
	At a fixed time $t$, a wave function $\psi: \mathbb{R} \rightarrow \mathbb{C}$ is called \textbf{square normalisable} if
	\[
		\int_{-\infty}^{\infty} |\psi(x)|^2 dx < \infty
	\]
	which means it has a probabilistic interpretation (as we can multiply it by a constant to make the probability of finding a particle anywhere equal to $1$).
\end{definition}

\begin{proposition}
	The set of continuous square-integrable wave functions forms a complex vector space. In particular, for all square-integrable wave functions $\psi_1, \psi_2$ and for every $a_1, a_2 \in \mathbb{C}$, the wave function
	\[
		a_1 \psi_1 + a_2 \psi_2
	\]
	is also square-integrable.
\end{proposition}

\begin{proof}
	Clearly, if $\psi_1$ is square-integrable then for every $a_1 \in \mathbb{C}$, $a_1 \psi_1$ is square-integrable. So now we must prove $\psi_1 + \psi_2$ is square-integrable. For every $x \in \mathbb{R}$,
	\[
		\begin{aligned}
			|\psi_1(x) + \psi_2(x)|^2
				& = \langle \psi_1(x) + \psi_2(x), \psi_1(x) + \psi_2(x) \rangle \\
				& = \langle \psi_1(x) + \psi_2(x), \psi_1(x) \rangle + \langle \psi_1(x) + \psi_2(x), \psi_2(x) \rangle \\
				& = \langle \psi_1(x), \psi_1(x) \rangle + \langle \psi_2(x), \psi_1(x) \rangle + \langle \psi_1(x), \psi_2(x) \rangle + \langle \psi_2(x), \psi_2(x) \rangle \\
				& = \langle \psi_1(x), \psi_1(x) \rangle + \overline{\langle \psi_1(x), \psi_2(x) \rangle} + \langle \psi_1(x), \psi_2(x) \rangle + \langle \psi_2(x), \psi_2(x) \rangle \\
				& = |\psi_1(x)|^2 + |\psi_2(x)|^2 + 2 \Re(\overline{\psi_1(x)} \psi_2(x)) \\
				& \le |\psi_1(x)|^2 + |\psi_2(x)|^2 + 2 |\overline{\psi_1(x)} \psi_2(x)| \\
				& \le |\psi_1(x)|^2 + |\psi_2(x)|^2 + 2 |\overline{\psi_1(x)}| |\psi_2(x)| \\
				& = |\psi_1(x)|^2 + |\psi_2(x)|^2 + (|\psi_1(x)|^2 + |\psi_2(x)|^2) - {(|\psi_1(x)| + |\psi_2(x)|)}^2 \\
				& \le 2 |\psi_1(x)|^2 + 2 |\psi_2(x)|^2
		\end{aligned}
	\]
	Hence,
	\[
		\int_{-\infty}^{\infty} |\psi_1(x) + \psi_2(x)|^2 dx \le 2 \int_{-\infty}^{\infty} |\psi_1(x)|^2 + 2 \int_{-\infty}^{\infty} |\psi_2(x)|^2
	\]
	Hence $\psi_1 + \psi_2$ is square-integrable.
\end{proof}

\begin{definition}
	We define an \textbf{inner product} over the set of \textbf{wave functions} as
	\[
		\langle \psi_1, \psi_2 \rangle := \int_{-\infty}^{\infty} \overline{\psi_1(x)} \psi_2(x) dx
	\]
\end{definition}

\begin{proposition}
	The inner product defined above is a Hermitian inner product.
\end{proposition}

\begin{proof}
	Properties 1, 2 and 3 are clear from the definition. For property 4,
	\[
		\langle \psi, \psi \rangle := \int_{-\infty}^{\infty} |\psi(x)|^2 dx \ge 0
	\]
	as the integrand $|\psi(x)|^2$ is non-negative. If $\langle \psi, \psi \rangle = 0$, then $|\psi(x)|^2 = 0$ as $|\psi(x)|^2$ is continuous, hence $\psi(x) = 0$.
\end{proof}

\begin{definition}
	The vector space of wave functions with the Hermitian inner product above form a \textbf{Hilbert space}.
\end{definition}

\begin{definition}
	We define an \textbf{orthonormal basis for the set of wave functions} to be a set of wave functions $\{ \phi_n(x) \}$ such that
	\[
		\langle \phi_m, \phi_n \rangle = \delta_{m, n}
	\]
	and every continuous square-integrable wave function $\psi$ can be expressed uniquely as
	\[
		\psi(x) = \sum_n c_n \phi_n(x)
	\]
	where
	\[
		c_n = \langle \phi_n, \psi \rangle = \int_{-\infty}^{\infty} \overline{\phi_n(x)} \psi(x)
	\]
	This allows us to express the Hermitian inner product in terms of the $c_n$:
	\[
		\langle \psi_1, \psi_2 \rangle := \int_{-\infty}^{\infty} \overline{\psi_1(x)} \psi_2(x) dx = \sum_n \overline{c_{1, n}} c_{2, n}
	\]
	which gives the squared norm as
	\[
		\langle \psi, \psi \rangle = \int_{-\infty}^{\infty} |\psi(x)|^2 dx = \sum_n |c_n|^2
	\]
\end{definition}

\begin{example}\label{exa:infinitePotentialWellBasisFunctions}
	For an infinite potential well in the region $(0, L)$, we can restrict the square-integrable to ones that vanish outside $(0, L)$. For every $n \in \mathbb{N}$, define a basis
	\[
		\phi_n(x) = \sqrt{\frac{2}{L}} \sin \left( \frac{n \pi x}{L} \right)
	\]
	The $\phi_n$ are orthogonal with respect to the inner product:
	\[
		\begin{aligned}
			\langle \phi_m, \phi_n \rangle
				& = \int_{0}^{L} \overline{\phi_m(x)} \phi_n(x) dx \\
				& = \frac{2}{L} \sin \left( \frac{m \pi x}{L} \right) \sin \left( \frac{n \pi x}{L} \right) dx \\
				& = \frac{1}{L} \int_{0}^{L} \left( \cos \left( \frac{(m - n) \pi x}{L} \right) - \cos \left( \frac{(m + n) \pi x}{L} \right) \right) dx \\
				& = \delta_{m, n} - \delta_{m, -n} \\
				& = \delta_{m, n}
		\end{aligned}
	\]
	So any continuous square-integrable wave function in this region has the unique form
	\[
		\phi(x) = \sum_{n =0}^{\infty} c_n \phi_n(x) = \sqrt{\frac{2}{L}} \sum_{n = 1}^{\infty} \sin \left( \frac{n \pi x}{L} \right)
	\]
	This is precisely Fourier's theorem, with the Fourier coefficients $c_n$ given by
	\[
		c_n = \langle \phi_n, \psi \rangle = \sqrt{\frac{2}{L}} \int_{0}^{L} \sin \left( \frac{n \pi x}{L} \right) \psi(x) dx
	\]
	The norm squared of $\psi$ is
	\[
		\langle \psi, \psi \rangle = \int_{0}^{L} |\psi(x)|^2 dx = \sum_{n = 1}^{\infty} |c_n|^2
	\]
	which is the statement of Parseval's theorem.
\end{example}

\begin{example}
	Consider a pyramid wave function in an infinite potential well in $(0, L)$ defined as
	\[
		\psi(x) = \sqrt{\frac{12}{L}} \cdot \begin{cases}
			\frac{x}{L} & \text{ if } 0 \le x \le \frac{L}{2} \\
			\frac{L - x}{L} & \text{ if } \frac{L}{2} \le x \le L
		\end{cases}
	\]
	Then the Fourier coefficients are given by
	\[
		\begin{aligned}
			c_n
				& = \sqrt{\frac{2}{L}} \int_{0}^{L} \sin \left( \frac{n \pi x}{L} \right) \psi(x) dx \\
				& = \sqrt{\frac{24}{L^2}} \left( \int_{0}^{L / 2} \frac{x}{L} \sin \left( \frac{n \pi x}{L} \right) dx + \int_{L / 2}^{L} \left( 1 - \frac{x}{L} \right) \sin \left( \frac{n \pi x}{L} \right) dx \right) \\
				& = \sqrt{\frac{24}{L^2}} (1 - {(-1)}^n) \int_{0}^{L / 2} \frac{x}{L} \sin \left( \frac{n \pi x}{L} \right) dx \\
				& = \sqrt{24} (1 - {(-1)}^n) \frac{{(-1)}^{(n + 1)/2}}{n^2 \pi^2} \\
				& = \begin{cases}
					\frac{\sqrt{96} {(-1)}^{m + 1}}{{(2m + 1)}^2 \pi^2} & \text{ if } n = 2m + 1 \text{ for some } m \in \mathbb{N} \\
					0 & \text{ otherwise}
				\end{cases}
		\end{aligned}
	\]
	We see that
	\[
		\langle \psi, \psi \rangle = \sum_{n = 1}^{\infty} |c_n|^2 = \frac{96}{\pi^4} \sum_{m = 0}^{\infty} \frac{1}{{(2m + 1)}^4} = 1
	\]
\end{example}

\subsection{Hermitian operators}

\begin{definition}
	Let $V$ be a finite-dimensional complex vector space with Hermitian inner product $\langle \cdot, \cdot \rangle$ and an orthonormal basis $\{ e_j \}$. A \textbf{linear operator} is a map $A: V \rightarrow V$ which satisifes
	\[
		\forall v_1, v_2 \in V, \forall a_1, a_2 \in \mathbb{C}, \quad A (a_1 v_1 + a_2 v_2) = a_1 A(v_1) + a_2 A(v_2)
	\]
\end{definition}

\begin{remark}
	Any linear combination $a_1 A_1 + a_2 A_2$ and composition $A_1 \circ A_2$ of two linear operators $A_1$ and $A_2$ is also a linear operator.
\end{remark}

\begin{definition}
	The \textbf{matrix elements} of a linear operator $A$ in an orthonormal basis $\{ e_j \}$ are defined by
	\[
		A_{i, j} = \langle e_i, A \cdot e_j \rangle
	\]
\end{definition}

\begin{definition}
	The adjoint $A^{\dagger}$ of a linear operator $A$ is defined by
	\[
		\forall v_1, v_2 \in V, \quad \langle v_1, A v_2 \rangle = \langle A^{\dagger} v_1, v_2 \rangle
	\]
\end{definition}

\begin{proposition}
	$A^{\dagger}_{i, j} = \overline{A_{j, i}}$, i.e. $A^{\dagger}$ is the conjugate of the transpose of $A$.
\end{proposition}

\begin{proof}
	\[
		A^{\dagger}_{i, j} = \langle e_i, A^{\dagger} e_j = \langle A e_i, e_j \rangle = \overline{\langle e_j, A e_i} = \overline{A_{i, j}}
	\]
\end{proof}

\begin{proposition}
	The adjoint operation satisfies
	\begin{itemize}
		\item ${(a_1 A_1 + a_2 A_2)}^{\dagger} = \overline{a_1} A_1^{\dagger} + \overline{a_2} A_2^{\dagger}$.
		\item ${(A_1 A_2)}^{\dagger} = A_2^{\dagger} A_1^{\dagger}$.
	\end{itemize}
\end{proposition}

\begin{proof}
	TODO.
\end{proof}

\begin{corollary}
	For every $n \in \mathbb{N}$ and for every polynomial function $f$,
	\[
		{(A^n)}^{\dagger} = {(A^{\dagger})}^n, \quad {f(A)}^{\dagger} = f(A^{\dagger})
	\]
\end{corollary}

\begin{definition}
	A \textbf{Hermitian operator} $A$ is a linear operator that satisfies
	\[
		A = A^{\dagger}
	\]
	Equivalently,
	\[
		\forall v_1, v_2 \in V, \quad \langle v_1, A v_2 \rangle = \langle A v_1, v_2 \rangle \quad \text{or} \quad \overline{A_{j, i}} = A_{i, j}
	\]
	hence the matrix of a Hermitian operator is a Hermitian matrix.
\end{definition}

\begin{definition}
	The matrix elements of $A$, where $A$ is the Hermitian operator that acts on the space of wave functions with the Hermitian inner product defined as before, are given by
	\[
		A_{m, n} := \langle \phi_m, A (\phi_n) \rangle = \int_{-\infty}^{\infty} \overline{\phi_m(x)} A (\phi_n)
	\]
\end{definition}

\begin{definition}
	The \textbf{adjoint} $A^{\dagger}$ of a \textbf{linear differential operator} $A$ is defined by
	\[
		\langle \psi_1, A^{\dagger} (\psi_2) \rangle = \langle A(\psi_1), \psi_2 \rangle
	\]
	and has the same properties as the adjoint of a linear operator. Its matrix elements are given by
	\[
		A^{\dagger}_{m, n} = \overline{A_{n, m}}
	\]
\end{definition}

\begin{theorem}
	The position and momentum operators are Hermitian operators.
\end{theorem}

\begin{proof}
	For the position operator, $\hat{x}$:
	\[
		\begin{aligned}
			\langle \hat{x}(\psi_1), \psi_2 \rangle
				& = \int_{-\infty}^{\infty} \overline{x \psi_1(x)} \psi_2(x) dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi_1(x)} x \psi_2(x) dx \\
				& = \langle \psi_1, \hat{x}(\psi_2)
		\end{aligned}
	\]
	For the momentum operator, $\hat{p}$, by integrating parts:
	\[
		\begin{aligned}
			\langle \hat{p}(\psi_1), \psi_2 \rangle
				& = \int_{-\infty}^{\infty} \overline{-i \hbar \diffp{\psi_1(x)}{x}} \psi_2(x) dx \\
				& = \int_{-\infty}^{\infty} i \hbar \diffp{\overline{\psi_1(x)}}{x} \psi_2(x) dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi_1(x)} \left( -i \hbar \diffp{\psi_2(x)}{x} \right) dx + i \hbar {\left[ \overline{\psi_1(x)} \psi_2(x) \right]}_{\infty}^{\infty} \\
				& = \langle \psi_1, \hat{p}(\psi_2)
		\end{aligned}
	\]
	Since the wave functions must vanish as $|x| \rightarrow \infty$.
\end{proof}

\begin{definition}
	The \textbf{Hamiltonian operator} is defined as
	\[
		\hat{H}(\psi(x)) = \frac{\hat{p}^2 (\psi(x))}{2m} + V(x) = -\frac{\hbar^2}{2m} \diffp[2]{}{x} \psi(x) + V(x)
	\]
	and is a Hermitian operator. It relates to measurements of energy.
\end{definition}

\begin{example}
	For an infinite potential well in $[0, L]$, in Example~\ref{exa:infinitePotentialWellBasisFunctions}, we defined a basis
	\[
		\phi_n(x) = \sqrt{\frac{2}{L}} \sin \left( \frac{n \pi x}{L} \right)
	\]
	The matrix elements of position are given by
	\[
		\begin{aligned}
			x_{m, n}
				& := \langle \phi_m, \hat{x}(\phi_n) \rangle \\
				& = \int_{0}^{L} x \overline{\phi_m(x)} \phi_n(x) dx \\
				& = \frac{2}{L} \int_{0}^{L} x \sin \left( \frac{m \pi x}{L} \right) \sin \left( \frac{n \pi x}{L} \right) dx \\
				& = \frac{1}{L} \int_{0}^{L} x \left( \cos \left( \frac{(m - n) \pi x}{L} \right) - \cos \left( \frac{(m + n) \pi x}{L} \right) \right) dx \\
				& = \begin{cases}
					L / 2 & \text{ if } m = n \\
					\frac{4Lmn}{\pi^2 (m^2 - n^2)} ({(-1)}^{m + n} - 1) & \text{ if } m \ne n
				\end{cases}
		\end{aligned}
	\]
	using the substitution $y = \pi x \ l$ with the fact that for $n \ne 0$,
	\[
		\int_{0}^{\pi} y \cos(ny) dy = \frac{{(-1)}^n - 1}{n^2}
	\]
	The matrix elements $x_{m, n}$ form a Hermitian matrix.
\end{example}

\begin{example}
	For an infinite potential well in $[0, L]$, with the same basis functions as in the last example, the matrix elements of momentum are given by
	\[
		\begin{aligned}
			p_{m, n}
				& := \langle \phi_m, \hat{p}(\phi_n) \rangle \\
				& = -i \hbar \int_{0}^{L} \overline{\phi_m(x)} \diffp{\phi_n(x)}{x} dx \\
				& = -i \hbar \frac{2}{L} \sin \left( \frac{m \pi x}{L} \right) \frac{n \pi}{L} \cos \left( \frac{n \pi x}{L} \right) dx \\
				& = -\frac{i \hbar n \pi}{L^2} \int_{0}^{L} \left( \sin \left( \frac{(m + n) \pi x}{L} \right) + \sin \left( \frac{(m - n) \pi x}{L} \right) \right) dx \\
				& = \begin{cases}
					0 & \text{ if } m = n \\
					\frac{2i \hbar mn}{L (m^2 - n^2)} ({(-1)}^{m + n} - 1) & \text{ if } m \ne n
				\end{cases}
		\end{aligned}
	\]
	using the substitution $y = \pi x \ L$ with the fact that for $n \ne 0$,
	\[
		\int_{0}^{\pi} \sin(ny) = \frac{1 - {(-1)}^n}{n}
	\]
	The matrix elements $p_{m, n}$ form a Hermitian matrix.
\end{example}

\begin{example}
	For an infinite potential well in $[0, L]$, with the same basis functions as in the last example, the matrix elements of Hamiltonian operator are given by
	\[
		\begin{aligned}
			H_{m, n}
				& := \langle \phi_m, H(\phi_n) \rangle \\
				& = -\frac{\hbar^2}{2m} \int_{0}^{L} \overline{\phi_m(x)} \diffp[2]{\phi_n(x)}{x} dx \\
				& = E_n \frac{2}{L} \int_{0}^{L} \sin \left( \frac{m \pi x}{L} \right) \sin \left( \frac{n \pi x}{L} \right) dx \\
				& = E_n \delta_{m, n}
		\end{aligned}
	\]
	where
	\[
		E_n = \frac{\hbar^2 \pi^2 n^2}{2m L^2}
	\]
	The matrix elements $H_{m, n}$ form a diagonal matrix. The above calculation shows that the $\phi_n$ are eigenfunctions of the Hamiltonian operator, since
	\[
		\hat{H}(\phi_n(x)) = E_n \phi_n(x)
	\]
\end{example}

\subsection{The spectrum of a Hermitian operator}

\begin{definition}
	A wave function $\psi_a(x)$ is an \textbf{eigenfunction} of a Hermitian differential operator $A$ with eigenvalue $a$ if it satisfies
	\[
		A(\psi_a(x)) = a \psi_a(x)
	\]
\end{definition}

\begin{proposition}
	For a normalised eigenfunction $\psi_a(x)$ of a Hermitian differential operator $A$ with eigenvalue $a$,
	\begin{itemize}
		\item The expectation value of $A^n$ is $a^n$ for every $n \in \mathbb{N}$.
		\item The uncertainty of $A$ is $0$.
	\end{itemize}
\end{proposition}

\begin{proof}
	\hfill
	\begin{itemize}
		\item $\langle A^n \rangle = \langle \psi_a, A^n(\psi_a) \rangle = \langle \psi_a, a6n \psi_a \rangle = a^n \langle \psi_a, \psi_a \rangle = a^n$.
		\item $\Delta A = \sqrt{\langle A^2 \rangle - {\langle A \rangle}^2} = \sqrt{a^2 - a^2} = 0$.
	\end{itemize}
\end{proof}

\begin{remark}
	This means that $\psi_a$ is a wave function such that measurements of $A$ will be $a$ with probability $1$.
\end{remark}

\begin{theorem}
	Let $A$ be a Hermitian operator. Then
	\begin{enumerate}
		\item The eigenvalues of $A$ are real, and
		\item If two eigenfunctions $\psi_1(x), \psi_2(x)$ of $A$ have distinct eigenvalues $a_1 \ne a_2$, then $\psi_1(x)$ and $\psi_2(x)$ are orthogonal.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Let $\psi_1(x), \psi_2(x)$ be eigenfunctions of $A$ with eigenvalues $a_1$ and $a_2$, so
	\[
		A(\psi_1(x)) = a_1 \psi_1(x), \quad A(\psi_2(x)) = a_2 \psi_2(x)
	\]
	Then
	\[
		\begin{aligned}
			\langle \psi_1, A(\psi_2) \rangle & = \langle \psi_1, a_2 \psi_2 \rangle = a_2 \langle \psi_1, \psi_2 \rangle \\
			\langle A(\psi_2), \psi_1 \rangle & = \langle a_1 \psi_1, \psi_2 \rangle = \overline{a_1} \langle \psi_1, \psi_2 \rangle \\
			\Longrightarrow 0 & = (\overline{a_1} - a_2) \langle \psi_1, \psi_2 \rangle
		\end{aligned}
	\]
	If $a_1 = a_2$ and 4 then $(\overline{a_1} - a_1) \langle \psi, \psi \rangle = 0$, so if $\psi$ is non-zero, then $\overline{a_1} = a_1$, so $a_1 = a_2 \in \mathbb{R}$. If $a_1 \ne a_2$ then $(a_1 - a_2) \langle \psi_1, \psi_2 \rangle = 0 \Longrightarrow \langle \psi_1, \psi_2 \rangle = 0$
\end{proof}

\begin{definition}
	For a Hermitian operator $A$, a discrete spectrum of eigenvalues $\{ a_n \}$ is called \textbf{non-degenerate} if there is one linearly independent eigenfunction $\phi_n$ for each eigenvalue $a_n$.
\end{definition}

\begin{corollary}
	We can construct an orthonormal basis with normalised eigenfunctions $\phi_n$, so that
	\[
		\langle \phi_m, \phi_n \rangle = \delta_{m, n}
	\]
	This means any continuous square-integrable wave function $\psi$ has a unique expansion
	\[
		\psi(x) = \sum_n c_n \phi_n(x)
	\]
	where
	\[
		c_m = \langle \phi_m, \psi \rangle = \sum_n c_n \langle \phi_m, \phi_n \rangle = \sum_n c_n \delta_{m, n}
	\]
\end{corollary}

\begin{corollary}
	The norm of a wave function $\psi$ is
	\[
		\langle \psi, \psi \rangle = \sum_{m, n} \overline{c_m} c_n \langle \phi_m, \phi_n \rangle = \sum_n |c_n|^2
	\]
	and if $\psi$ is normalised, then
	\[
		\langle \psi, \psi \rangle = 1
	\]
	So the $|c_n|^2$ can be interpreted as the probability of a measurement of $A$ being $a_n$.
\end{corollary}

\begin{example}
	In an infinite potential well in $(0, L)$, the $\phi_n$ defined in Example~\ref{exa:infinitePotentialWellBasisFunctions} eigenfunctions for the Hamiltonian operator $\hat{H}$ with eigenvalues
	\[
		E_n = \frac{\hbar^2 \pi^2 n^2}{2m L^2}
	\]
	So every wave function $\psi$ can be written as
	\[
		\psi(x) = \sum_{n > 0} c_n \phi_n(x)
	\]
	and $|c_n|^2$ is the probability that a measurement of energy will be $E_n$. These probabilities summing to $1$ agrees with Parseval's theorem.
\end{example}

\begin{definition}
	A Hermitian operator $A$ can have a continuous spectrum of eigenvalues instead a discrete one. Here, we cannot choose eigenfunctions to form a complete orthonormal basis as before. To help with this case, we define the \textbf{Dirac delta function}, $\delta$, (which is not actually a function but a distribution). Roughly speaking,
	\[
		\delta(a) = \begin{cases}
			0 & \text{ if } a \ne 0 \\
			\infty & \text{ if } a = 0
		\end{cases}
	\]
	$\delta$ also satisfies
	\[
		\int_{-\infty}^{\infty} \delta(a) da = 1
	\]
	$\delta$ can be more precisely defined as the limit of the Gaussian function
	\[
		\delta_{\epsilon} (a) = \frac{1}{\epsilon \sqrt{\pi}} e^{-a^2 / \epsilon^2}
	\]
	as $\epsilon \rightarrow 0^+$.
\end{definition}

\begin{proposition}
	(\textbf{Properties of the Dirac delta function})
	\begin{enumerate}
		\item For every continuous function $f(a)$,
		\[
			\int_{-\infty}^{\infty} \delta(a - a') f(a') da = f(a)
		\]
		\item The Dirac delta function is the Fourier transform of $1$:
		\[
			\delta(a) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{i a a'} da'
		\]
		This implies that $\delta(a) = \delta(-a) = \overline{\delta(a)}$.
	\end{enumerate}
\end{proposition}

\begin{remark}
	Property 1 in the above proposition is the continuous version of $\sum_n \delta_{m, n} f_n = f_m$, so $\delta(a - a')$ is the continuous version of the identity matrix $\delta_{m, n}$.
\end{remark}

\begin{proposition}
	For a Hermitian operator $A$ with a continuous spectrum, there exists a basis of eigenfunctions $\phi_a(x)$ with eigenvalues $a \in \mathbb{R}$ that satisfy
	\[
		\langle \phi_a, \phi_{a'} \rangle = \delta(a - a')
	\]..
\end{proposition}

\begin{corollary}
	Eigenfunctions $\phi_a(x)$ are therefore not square-normalisable since $\langle \phi_a, \phi_a \rangle = \infty$. However, every square-normalisable wave function can be uniquely expanded as
	\[
		\psi(x) = \int_{-\infty}^{\infty} c(a) \phi_a(x) da
	\]
	where $c(a)$ are complex coefficients that are continuous functions of $a$. $c(a)$ are given by
	\[
		\begin{aligned}
			c(a)
				& = \int_{-\infty}^{\infty} c(a') \delta(a - a') da' \\
				& = \int_{-\infty}^{\infty} c(a') \langle \phi_a, \phi_{a'} \rangle da' \\
				& = \langle \phi_a, \psi \rangle
		\end{aligned}
	\]
	which is the continuous version of $\langle \phi_n, \psi \rangle = c_n$.
\end{corollary}

\begin{corollary}
	The norm of a wave function $\psi$ can be written as
	\[
		\begin{aligned}
			\langle \psi, \psi \rangle
				& = \int_{-\infty}^{\infty} \overline{c(a)} c(a') \langle \phi_a, \phi_{a'} \rangle da da' \\
				& = \int_{-\infty}^{\infty} \overline{c(a)} c(a') \delta(a - a') da da' \\
				& = \int_{-\infty}^{\infty} |c(a)|^2 da
		\end{aligned}
	\]
	which is the continuous version of $\langle \psi, \psi \rangle = \sum_n |c_n|^2$.

	Note that for a normalised wave function $\psi$,
	\[
		\langle \psi, \psi \rangle = \int_{-\infty}^{\infty} |c(a)|^2 da = 1
	\]
	so $|c(a)|^2$ can be interpreted as a probability distribution for measurements of $A$.
\end{corollary}

\begin{example}
	The eigenfunctions of the momentum operator $\hat{p} = -i \hbar \diffp{}{x}$ are $e^{ipx / \hbar}$ with eigenvalue $p$. We normalise these eigenfunctions, choosing
	\[
		\phi_p(x) = \frac{1}{\sqrt{2 \pi \hbar}} e^{ipx / \hbar}
	\]
	which gives
	\[
		\langle \psi_p, \psi_{p'} \rangle = \frac{1}{2 \pi \hbar} \int_{-\infty}^{\infty} e^{i(p - p')x / \hbar} dx = \delta(p - p')
	\]
	So we can write a wave function $\psi$ as
	\[
		\psi(x) = \int_{-\infty}^{\infty} c(p) \phi_p(x) dp = \frac{1}{\sqrt{2 \pi \hbar}} \int_{-\infty}^{\infty} c(p) e^{ipx / \hbar} dp
	\]
	which is the result of the Fourier transform.
\end{example}

\subsection{The Postulates of Quantum Mechanics}

\begin{definition}
	The \textbf{postulates of quantum mechanics} are the following:
	\begin{enumerate}
		\item A particle is described by a normalised wave function $\psi(x)$.
		\item Measurable quantities or observables are represented by Hermitian operators $A(x, p)$, where $x$ is position and $p$ is momentum, which are constructed polynomial or real analytic function of the position and momentum operators:
		\[
			\begin{aligned}
				\hat{x} & = x \\
				\hat{p} & = -i \hbar \diffp{}{x}
			\end{aligned}
		\]
		E.g. the Hamiltonian operator is $\hat{H} = \frac{\hat{p}^2}{2m} + V(x)$.
		\item The possible values of a measurement of $A$ are its eigenvalues $a$.
		\begin{itemize}
			\item If the eigenvalues $\{ a_j \}$ are discrete, then with a basis of eigenfunctions $\phi_j(x)$ which satisfy $\langle \phi_i, \phi_j \rangle = \delta_{i, j}$, the probability of measuring $a_j$ is $P_j := |\langle \phi_j, \psi \rangle|^2$.
			\item If the eigenvalues $a \in \mathbb{R}$ are continuous, then with a basis of eigenfunctions $\phi_a(x)$ which satisfy $\langle \phi_a, \phi_{a'} \rangle = \delta(a - a')$, the probability density function is given by $P(a) := |\langle \phi_a, \psi \rangle|^2$.
		\end{itemize}
		\item Immediately after a measurement of $A$ yielding $a_j$ ($a$ for the continuous case), the wave function is $\phi_j(x)$ ($\phi_a(x)$ for the continuous case).
		\item If no measurements are taken, the wave function evolution in time is determined by the Schrodinger equation:
		\[
			i \hbar \diffp{\psi(x, t)}{t} = \hat{H} \psi(x, t)
		\]
	\end{enumerate}
\end{definition}

\begin{corollary}
	Observable quantities are represented by Hermitian operators, which have real eigenvalues, hence the outcomes of measurements are real numbers.
\end{corollary}

\begin{remark}
	In this case that the eigenvalues are discrete, the wave function can be written as a sum of the orthonormal basis eigenfunctions as
	\[
		\sum_j c_j \phi_j(x)
	\]
	where $c_j = \langle \phi_j, \psi \rangle$. The probability of measuring $a_j$ is $P_j = |c_j|^2$, which means the probabilities add to $1$, since the wave function is normalised:
	\[
		\langle \psi, \psi \rangle = \sum_j |c_j|^2 = \sum_j P_j = 1
	\]
\end{remark}

\begin{remark}
	In the case that the eigenvalues are continuous, the wave function can be written as an integral
	\[
		\psi(x) = \int_{-\infty}^{\infty} c(a) \phi_a(x) da
	\]
	where $c(a) = \langle \phi_a, \psi \rangle$. The probability density function is given by $P(a)) = |c(a)|^2$, and the wave function is normalised so
	\[
		\langle \psi, \psi \rangle = \int_{-\infty}^{\infty} |c(a)|^2 da = \int_{-\infty}^{\infty} P(a) da = 1
	\]
\end{remark}

\begin{remark}
	In the continuous case, assuming a measurement of infinite accuracy, after the wave function collapses to $\phi_a(x)$ due to a measurement $a$ of $A$, the wave function immediately aftewards is no longer square-normalisable:
	\[
		\langle \phi_a, \phi_a \rangle = \infty
	\]
	Real-world measurements have an uncertainty $\epsilon$, which means the wave function immediately after the measurement is instead
	\[
		\int \delta_{\epsilon} (a - a') \phi_{a'}(x) da'
	\]
	where $\delta_{\epsilon}(a - a')$ has a sharp peak of width $\epsilon$ around $a' = a$, which corresponds to the case where the accuracy is infinite, since $\delta_{\epsilon}(a - a') \to \delta(a - a')$ as $\epsilon \to 0$.
\end{remark}

\begin{definition}
	The \textbf{expectation value} of a Hermitian operator is defined as
	\[
		\langle A \rangle = \langle \psi, A \psi \rangle = \int_{-\infty}^{\infty} \overline{\psi(x)} A \psi(x) dx
	\]
\end{definition}

\begin{proposition}
	Let $A$ be a hermitian operator with discrete eigenvalues $a_j$ and let $\phi_j$ be an orthonormal basis of eigenfunctions of $A$. Then the expectation value of $A$ is
	\[
		\langle A \rangle = \sum_j a_j P_j
	\]
	where $P_j = |\langle \phi_j, \psi \rangle|^2$.
\end{proposition}

\begin{proof}
	\[
		\begin{aligned}
			\langle A \rangle & = \sum_{i, j} \overline{c_i} c_j \langle \phi_i, A \phi_j \rangle = \sum_{i, j} a_j \overline{c_i} c_j \langle \phi_i, \phi_j \rangle \\
			& = \sum_j a_j |c_j|^2 = \sum_j a_j P_j
		\end{aligned}
	\]
	where $c_i$ is the coefficient of $\phi_i$ in the expansion of the wave function $\psi$, $c_i = \langle \phi_i, \psi \rangle$.
\end{proof}

\begin{proposition}
	Let $A$ be a hermitian operator with continuous eigenvalues $a$ and eigenfunctions $\phi_a(x)$. Then the expectation value of $A$ is
	\[
		\langle A \rangle = \int_{-\infty}^{\infty} a P(a) da
	\]
	where $P(a) = |\langle \phi_a, \psi \rangle|^2$.
\end{proposition}

\begin{proof}
	\[
		\begin{aligned}
			\langle A \rangle & = \int_{-\infty}^{\infty} \overline{\psi(x)} A \psi(x) dx \\
			& = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \overline{c(a)} c(a') \langle \phi_a, A \phi_{a'} \rangle da \ da' \\
			& = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \overline{c(a)} c(a') a' \langle \phi_a, \phi_{a'} \rangle da \ da' \\
			& = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \overline{c(a)} c(a') a' \delta(a - a') da \ da' \\
			& = \int_{-\infty}^{\infty} a |c(a)|^2 da = \int_{-\infty}^{\infty} a P(a) da
		\end{aligned}
	\]
\end{proof}

\begin{example}
	The position operator, $\hat{x} = x$, multiplies a wave function by $x$. The position operator has a continuous spectrum with an orthonormal basis of eigenfunctions given by
	\[
		\phi_{x'}(x) = \delta(x - x')
	\]
	These are eigenfunctions with eigenvalue $x'$ since
	\[
		\hat{x} \phi_{x'}(x) = x \delta(x - x') = x' \delta(x - x') = x' \phi_{x'}(x)
	\]
	They are also orthonormal, since
	\[
		\langle \phi_{x_1}, \phi_{x_2} \rangle = \int_{-\infty}^{\infty} \phi_{x_1}(x) \phi_{x_2}(x) dx = \int_{-\infty}^{\infty} \delta(x - x_1) \delta(x - x_2) dx = \delta(x_1 - x_2)
	\]
	$\phi_{x'}$ can be viewed as a wave function immediately a measurement of position with infinite accuracy. Note it is not square-normalisable: $\langle \phi_{x'}, \phi_{x'} \rangle = \delta(x' - x') = \delta(0) = \infty$. Any wave function $\psi$ can be expanded in this basis:
	\[
		\psi(x) = \int_{-\infty}^{\infty} c(x') \phi_{x'}(x) dx' = \int_{-\infty}^{\infty} c(x') \delta(x - x') dx' = c(x)
	\]
	The probability density function for position is therefore
	\[
		P(x) = |\langle \phi_{x}, \psi \rangle|^2 = \left| \int_{-\infty}^{\infty} \delta(x - x') \psi(x') dx' \right|^2 = |\psi(x)|^2
	\]
\end{example}

\begin{example}
	The momentum operator, $\hat{p} = -i \hbar \diffp{x}{x}$, has a continuous spectrum with an orthonormal basis of eigenfunctions given by
	\[
		\phi_p(x) = \frac{1}{\sqrt{2 \pi \hbar}} e^{ipx / \hbar}
	\]
	They are orthonormal, since
	\[
		\langle \phi_p, \phi_{p'} \rangle = \frac{1}{2 \pi \hbar} \int_{-\infty}^{\infty} e^{i(p' - p)x / \hbar} dp = \delta(p - p')
	\]
	They are not square-normalisable, since $\langle \phi_p, \phi_p \rangle = \delta(p - p) = \delta(0) = \infty$. Any wave function $\psi$ can be expanded in this basis:
	\[
		\psi(x) = \int_{-\infty}^{\infty} c(p) \phi_p(x) = \frac{1}{2 \pi \hbar} \int_{-\infty}^{\infty} c(p) e^{ipx / \hbar} dp
	\]
	where
	\[
		c(p) = \langle \phi_p, \psi \rangle = \int_{-\infty}^{\infty} \overline{\phi_p(x)} \psi(x) dx = \frac{1}{2 \pi \hbar} \int_{-\infty}^{\infty} \overline{e^{ipx / \hbar}} \psi(x) dx
	\]
	The probability density function for momentum is therefore
	\[
		\tilde{P}(p) = |c(p)|^2
	\]
\end{example}

\subsection{Commutators and the uncertainty principle}

\begin{definition}
	Let $A$ and $B$ be linear operatorrs. The \textbf{commutator} of $A$ and $B$ is defined as
	\[
		[A, B] := AB - BA
	\]
\end{definition}

\begin{definition}
	Let $A$ and $B$ be linear operators. The \textbf{anti-commutator} of $A$ and $B$ is defined as
	\[
		\{ A, B \} := AB + BA
	\]
\end{definition}

\begin{proposition}
	(\textbf{Properties of the commutator}) Let $A$, $B$ and $C$ be linear operators, and $a_1, a_2$ scalars. The commutator satisfies the following properties:
	\begin{enumerate}
		\item (\textbf{Anti-symmetry}) $[A, B] = -[B, A]$.
		\item (\textbf{Linearity}) $[a_1 A_1 + a_2 A_2, B] = a_1 [A_1, B] + a_2 [A_2, B]$.
		\item $[A, BC] = B[A, C] + [A, B]C$.
		\item (\textbf{Jacobi identity}) $[A, [B, C]] + [B, [C, A]] + [C, [A, B]] = 0$.
	\end{enumerate}
\end{proposition}

\begin{proof}
	Omitted.
\end{proof}

\begin{theorem}\label{thm:commutingOperatorsHaveSameEigenfunctions}
	(\textbf{Two commuting matrices are simultaneously diagonalisable}) Let $A$ and $B$ be Hermitian operators and $[A, B] = 0$. Then there exists an orthonormal basis of wave functions that are eigenfunctions of both $A$ and $B$.
\end{theorem}

\begin{proof}
	We prove the case where the spectrum of eigenvalues $\{ a_j \}$ of $A$ is discrete and non-degenerate, so up to normalisation there exists a unique solution to $A \phi_j(x) = a_j \phi_j(x)$ for each eigenvalue $a_j$. We can normalise the solutions to make an orthonormal basis, so that $\langle \phi_, \phi_j \rangle = \delta_{i, j}$.

	We want to show $\phi_j$ is also an eigenfunction of $B$. $[A, B] = 0 \Longleftrightarrow AB = BA$ so
	\[
		A(B \phi_j) = B (A \phi_j) = B(a_j \phi_j) = a_j (B \phi_j)
	\]
	hence $B \phi_j$ is also an eigenfunction of $A$ with eigenvalue $a_j$. But eigenfuntions with eigenvalue $a_j$ are unique up to normalisation, hence $B \phi_j(x) = b_j \phi_j(x)$ for some $b_j$.
\end{proof}

\begin{definition}
	Let $A$ and $B$ be Hermitian operators which represent observable quantities. $A$ and $B$ are called \textbf{compatible} if their commutator vanishes: $[A, B] = 0$.
\end{definition}

\begin{proposition}
	The position operator $\hat{x}$ and momentum operator $\hat{p}$ are not compatible.
\end{proposition}

\begin{proof}
	Let $\psi$ be a wave function, then
	\[
		[\hat{x}, \hat{p}] \psi = x \left( -i\hbar \diffp{\psi}{x} \right) + i \hbar \diffp{}{x} (x \psi) = i \hbar \psi
	\]
	Hence $[\hat{x}, \hat{p}] = i\hbar \ne 0$.
\end{proof}

\begin{proposition}
	The momentum operator $\hat{p}$ and the Hamiltonian operator $\hat{H} = \frac{\hat{p}^2}{2m} + V(x)$ are compatible iff $V(x)$ is a constant.
\end{proposition}

\begin{proof}
	We have that $[\hat{H}, \hat{p}] = [V(x), \hat{p}] = i\hbar \diffp{V(x)}{x}$.
\end{proof}

\begin{proposition}
	The position operator $\hat{x}$ and the Hamiltonian operator $\hat{H}$ are not compatible.
\end{proposition}

\begin{proof}
	\[
		[\hat{H}, \hat{x}] = \frac{1}{2m} [\hat{p}^2, \hat{x}] = \frac{1}{2m} (\hat{p} [\hat{p}, \hat{x}] + [\hat{p}, \hat{x}] p) = -\frac{i\hbar}{m} \hat{p} \ne 0
	\]
\end{proof}

\begin{example}
	Let $A$ be a measurable quantity for which we measure a value of $a_j$. Then wave function immediately after the measurement is the associated eigenfunction $\phi_j$.

	If we measure $A$ immediately after this, the measurement will be $a_j$ with probability $1$, since $\phi_j$ is an eigenfunction of $A$. This corresponds with the uncertainty of $A$ vanishing:
	\[
		\begin{aligned}
			{(\Delta A)}^2 & = \langle A^2 \rangle - {\langle A \rangle}^2 = \langle \phi_j, A^2 \phi_j \rangle - {\langle \phi_j A, \phi_j \rangle}^2 \\
			& = a_j^2 \langle \phi_j, \phi_j \rangle - {(a_j \langle \phi_j, \phi_j \rangle)}^2 = a_j^2 - a_j^2 = 0
		\end{aligned}
	\]
	Now if we measure $B$ immediately after this:
	\begin{itemize}
		\item If $[A, B] = 0$, $\phi_j$ is also an eigenfunction of $B$ with eigenvalue $b_j$ by Theorem~\ref{thm:commutingOperatorsHaveSameEigenfunctions}, so a measurement of $B$ yields $b_j$ with probability $1$. Similarly, $\Delta B = 0$.
		\item If $[A, B] \ne 0$, $\phi_j$ is not an eigenfunction of $B$ and there are multiple possible outcomes. If the measurement of $B$ yields an eigenvalue $b$, then the wave function now becomes the eigenfunction corresponding to $b$, so $\Delta B = 0$, but now $\Delta A > 0$.
	\end{itemize}
\end{example}

\begin{remark}
	Note that ``immediately after'' here means the measurements are taken without time between them. Generally, if there is time between the measurements, then the wave function will evolve in between, so the measurement of $A$ will not yield $a_j$ with probability $1$, although eigenstates of the Hamiltonian operator and operators which commute with it do remain eigenstates under time evolution.
\end{remark}

\begin{theorem}
	(\textbf{The generalised uncertainty principle}) For every square-normalisable wave function,
	\[
		\Delta A \Delta B \ge \frac{1}{2} | \langle [A, B] \rangle |
	\]
\end{theorem}

\begin{proof}
	We prove the case that $\langle A \rangle = \langle B \rangle = 0$. We have
	\[
		{(\Delta A)}^2 = \langle A^2 \rangle = \langle \psi, A^2 \psi \rangle = \langle A \psi, A \psi \rangle
	\]
	and similarly for $B$, so we have
	\[
		{(\Delta A)}^2 {(\Delta B)}^2 = \langle A \psi, A \psi \rangle \langle B \psi, B \psi \rangle \ge |\langle A \psi, B \psi \rangle|^2
	\]
	by the Cauchy-Schwartz inequality. Now
	\[
		\begin{aligned}
			\langle A \psi, B \psi \rangle & = \langle AB \rangle \\
			& = \frac{1}{2} \langle (AB - BA) \rangle + \frac{1}{2} \langle (AB + BA) \rangle \\
			& = \frac{1}{2} \langle [A, B] \rangle + \frac{1}{2} \langle \{ A, B \} \rangle
		\end{aligned}
	\]
	$[A, B]$ is anti-Hermitian, so $\langle [A, B] \rangle \in i \mathbb{R}$, and $\{ A, B \}$ is Hermitian, so $\langle \{ A, B \} \rangle \in \mathbb{R}$. Taking the modulus of both sides, we get
	\[
		|\langle A \psi, B \psi \rangle|^2 = \frac{1}{4} |\langle [A, B] \rangle|^2 + \frac{1}{4} |\langle \{ A, B \} \rangle|^2 \ge \frac{1}{4} |\langle [A, B] \rangle|^2
	\]
	which completes the proof.
\end{proof}

\begin{example}
	For position and momentum, we have
	\[
		\Delta x \Delta p \ge \frac{1}{2} \hbar
	\]
	which is \textbf{Heisenberg's uncertainty principle}.
\end{example}

\begin{example}
	For momentum and energy, we have
	\[
		\Delta \Delta H \ge \frac{\hbar}{2} \langle V'(x) \rangle
	\]
	which vanishes if $V(x)$ is constant.
\end{example}

\begin{example}
	For position and energy, we have
	\[
		\Delta x \Delta H \ge \frac{\hbar}{2m} \langle p \rangle
	\]
	which means square-normalisable eigenfunctions of the Hamiltonian must have $\langle p \rangle = 0$.
\end{example}

\subsection{Energy}

\begin{example}
	In an infinite potential well,
	\[
		V(x) = \begin{cases}
			0 \text{ if } 0 < x < L \\
			\infty \text{ otherwise}
		\end{cases}
	\]
	the spectrum of the Hamiltonian is discrete and non-degenerate with eigenvalues
	\[
		E_n = \frac{\hbar^2 n^2 \pi^2}{2mL^2}
	\]
\end{example}

\begin{theorem}
	Let the potential of a particle be bounded below, so $V(x) \ge V_0$ for every $x \in \mathbb{R}$, and let $V(x_0) = V_0$ be the minimum. Thne if the wave function is normalised, $\langle H \rangle > V_0$.
\end{theorem}

\begin{proof}
	The energy expectation value is
	\[
		\begin{aligned}
			\langle H \rangle & = \langle \psi, \bar{H} \psi \rangle \\
			& = \frac{1}{2m} \langle \psi, \hat{p}^2 \psi \rangle + \langle \psi, V \psi \rangle \\
			& = \frac{1}{2m} \langle \hat{p} \psi, \hat{p} \psi \rangle + \langle \psi, V \psi \rangle \\
			& \ge \langle \psi, V \psi \rangle = \int_{-\infty}^{\infty} V(x) |\psi(x)|^2 dx
			& \ge V_0 \int_{-\infty}^{\infty} |\psi(x)|^2 dx = V_0
		\end{aligned}
	\]
	Now we show that $\langle H \rangle \ne V_0$. For equality to hold, $\langle \hat{p} \psi, \hat{p} \psi \rangle = 0$, so
	\[
		0 = \hat{p} \psi = -i\hbar \diffp{\psi(x)}{x} \Longrightarrow \psi(x) = c
	\]
	where $c \in \mathbb{C}$ is a constant. But $\psi$ is normalised, so $\psi(x) \to 0$ as $x \to \pm\infty$, hence $c = 0$, but then $\psi$ would not integrate to $1$. So $\langle H \rangle > V_0$.
\end{proof}

\begin{corollary}
	Let $\psi(x)$ be a normalised eigenfunction of $H$ with eigenvalue $E$. Then $E > V_0$.
\end{corollary}

\begin{proof}
	By the previous theorem, $\langle H \rangle = \langle \psi, H \psi \rangle = E \langle \psi, \psi \rangle = E > V_0$.
\end{proof}

\begin{definition}
	The smallest eigenvalue $E$ of the Hamiltonian is called the \textbf{zero-point energy}.
\end{definition}

\begin{theorem}
	The spectrum of the Hamiltonian is non-degenerate.
\end{theorem}

\begin{proof}
	Let $\psi_1$ and $\psi_2$ be two square-normalisable eigenfunctions with the same eigenvalue $E$. We will show that $\psi_1 = k \psi_2$ for some constant $k$. We have
	\[
		\hat{H} \psi_1(x) = -\frac{-\hbar}{2m} \partial_x^2 \psi_1(x) + V(x) \psi_1(x) = E \psi_1(x) \\
		\hat{H} \psi_2(x) = -\frac{-\hbar}{2m} \partial_x^2 \psi_2(x) + V(x) \psi_2(x) = E \psi_2(x)
	\]
	Multiplying the top equation by $\psi_2(x)$ and subtracting it from the bottom equation multiplied by $\psi_1(x)$ gives
	\[
		0 = \psi_1 \partial_x^2 \psi_2 - \psi_2 \partial_x^2 \psi_1 = \partial_ (\psi_1 \partial_x \psi_2 - \psi_2 \partial_x \psi_1)
	\]
	Hence
	\[
		\psi_1 \partial_x \psi_2 - \psi_2 \partial_x \psi_1 = c
	\]
	for some $c \in \mathbb{C}$. But $\psi_1$ and $\psi_2$ are square-normalisable, so vanish as $x \to \pm\infty$, hence $c = 0$. So we have
	\[
		\begin{aligned}
			\psi_1 \partial_x \psi_2 - \psi_2 \partial_x \psi_1 & = 0 \\
			\Longrightarrow \frac{\partial_x \psi_1}{\psi_1} - \frac{\partial_x \psi_2}{\psi_2} & = 0 \\
			\Longrightarrow \partial_x (\log(\psi_1) - \log(\psi_2)) & = 0 \\
			\Longrightarrow \log \left( \frac{\psi_1}{\psi_2} \right) = A \\
			\Longrightarrow \psi_1 = e^A \psi_2
		\end{aligned}
	\]
	for some constant $A \in \mathbb{C}$. Hence $\psi_1$ and $\psi_2$ are the same eigenfunction, up to scalar multiplication.
\end{proof}

\subsection{Stationary states}

\begin{proposition}
	Let $\psi(x)$ be an wave function at time $t = 0$. Then
	\[
		\psi(x, t) = \phi(x) e^{-iEt/\hbar}
	\]
	is a solution to the Schrodinger equation, where $\phi(x) = \psi(x, 0)$ is an eigenfunction of the Hamiltonian with eigenvalue $E$.
\end{proposition}

\begin{proof}
	Write the wave function as the product of functions of position and time:
	\[
		\psi(x, t) = \phi(x) T(t)
	\]
	Substituting this into Schrodinger's equation gives
	\[
		i\hbar \frac{1}{T(t)} \diffp{T(t)}{t} = -\frac{\hbar^2}{2m} \frac{1}{\phi(x)} \diffp[2]{\phi(x)}{x} + V(x)
	\]
	The left hand side is a function of only $t$ and the right hand side is a function of only $x$, so both sides equal a constant:
	\[
		i\hbar \frac{1}{T(t)} \diffp{T(t)}{t} = E = -\frac{\hbar^2}{2m} \frac{1}{\phi(x)} \diffp[2]{\phi(x)}{x} + V(x)
	\]
	This gives $T(t) = e^{-iEt/\hbar}$, and that $\phi$ is an eigenfunction of the Hamiltonian with eigenvalue $E$. $\bar{H}$ is a Hermitian operator so $E \in \mathbb{R}$.
\end{proof}

\begin{corollary}
	Schrodinger's equation is linear, so all possible of solutions are linear combinations of the stationary wave functions. Let $\phi(x, 0)$ be an initial wave function, then the following procedure generates a solution of Schrodingers equation $\psi(x, t)$ at time $t > 0$:
	\begin{enumerate}
		\item Construct an orthonormal basis of Hamiltonian eigenfunctions $\phi_j(x)$ with eigenvalues $E_j$, which gives stationary wave functions
		\[
			\psi_j(x, t) = \phi_j(x) e^{-iE_jt/\hbar}
		\]
		These wave functions are orthogonal for every $t$:
		\[
			\langle \psi_i, \psi_j \rangle = |e^{i(E_i - E_j)t \ \hbar}| \langle \phi_i, \phi_j \rangle = |e^{i(E_i - E_j)t \ \hbar}| \delta_{i, j} = \delta_{i, j}
		\]
		\item Expand the initial wave function $\psi(x, 0)$ as a linear combination of the orthonormal basis of Hamiltonian eigenfunctions,
		\[
			\psi(x, 0) = \sum_j c_j \phi_j(x)
		\]
		The wave function is normalised iff $\langle \psi, \psi \rangle = \sum_j |c_j|^2 = 1$.
		\item The general solution $\psi(x, t)$ is then
		\[
			\psi(x, t) = \sum_j c_j \psi_j(x, t) = \sum_j c_j \phi_j(x) e^{-iE_j t / \hbar}
		\]
		This is indeed a solution since Schrodingers equation is linear, and coincides with the initial wave function $\psi(x, 0)$ at $t = 0$. This solution is unique.
	\end{enumerate}
\end{corollary}

\begin{example}
	Define the normalised initial wave function
	\[
		\psi(x, 0) = c_1 \phi_1(x) + c_2 \phi_2(x)
	\]
	where $|c_1|^2 + |c_2|^2 = 1$. The wave function at later times is then
	\[
		\psi(x, t) = c_1 \psi_1(x, t) + c_2 \psi_2(x, t) = c_1 \phi_1(x) e^{-iE_1 t / \hbar} + c_2 \phi_2(x) e^{-iE_2 t / \hbar}
	\]
	The possible outcomes of energy measurements are $E_1$, with probability $P_1 = |c_1|^2$ and $E_2$, with probability $|c_2|^2$. The probabiilty density is
	\[
		\begin{aligned}
			P(x, t) & = |\psi(x, t)|^2
			& = |c_1 \phi_1(x) e^{-iE_1 t / \hbar} + c_2 \phi_2(x) e^{-iE_2 t / \hbar}|^2 \\
			& = |c_1|^2 |\phi_1(x)|^2 + |c_2|^2 |\phi_2(x)|^2 + 2 \Re(c_1 \overline{c_2} \phi_1(x) \overline{\phi_2(x)} e^{-i(E_1 - E_2)t/\hbar})
		\end{aligned}
	\]
	So the probability density and position expectation values oscillate in time with frequency $\omega = (E_2 - E_1) / \hbar$.
\end{example}

\begin{example}
	Consider the infinite potential well $0 < x < L$ with initial wave function
	\[
		\psi(x, 0) = \frac{1}{\sqrt{2}} (\phi_1(x) + \phi_2(x))
	\]
	The unique solution to Schrodinger's equation is
	\[
		\psi(x, t) = \frac{1}{\sqrt{2}} (\phi_1(x) e^{-iE_1 t / \hbar} + \phi_2(x) e^{-iE_2 t / \hbar})
	\]
	The possible outcomes of energy measurements are $E_1$, with probability $1 / 2$, and $E_2$, with probability $1 / 2$. The probability density is
	\[
		\begin{aligned}
			P(x, t) & = |\psi(x, t)|^2 \\
			& = \frac{1}{L} \left( {\sin (\pi x / L)}^2 + {\sin (2 \pi x / L)}^2 + 2\sin(\pi x / L) \sin(2 \pi x / L) \cos(\omega t) \right)
		\end{aligned}
	\]
	where
	\[
		\omega = (E_2 - E_1) / \hbar = \frac{3\hbar\pi^2}{2mL^2}
	\]
\end{example}

\begin{example}
	Consider a free particle moving on a line, so the potential is a constant, $V(x) = V_0$ (assume $V_0 = 0$). The momentum eigenfunctions are solutions to
	\[
		-i\hbar\diffp{}{x} \phi_p(x) = p \phi_p(x)
	\]
	which has solutions
	\[
		\phi_p(x) = \frac{1}{\sqrt{2\pi\hbar}} e^{ipx/\hbar}
	\]
	for every $p \in \mathbb{R}$. The momentum operator therefore has a continuous spectrum, so we choose a normalisatio satisfying
	\[
		\begin{aligned}
			\langle \phi_p, \phi_{p'} \rangle & = \int_{-\infty}^{\infty} \overline{\phi_p(x)} \phi_{p'}(x) dx \\
			\frac{1}{\sqrt{2\pi\hbar}} \int_{-\infty}^{\infty} e^{-i(p - p')x / \hbar} dx \\
            & = \delta(p - p')
		\end{aligned}
	\]
    The spectrum is also non-degenerate as there is a unique eigenfunction $\phi_p(x)$ for every eigenvalue $p$. These same eigenfunctions are also eigenfunctions of the Hamiltonian operator:
    \[
        \hat{H} \phi_p(x) = -\frac{\hbar^2}{2m}\diffp[2]{}{x} \phi_p(x) = E_p \phi_p(x)
    \]
    where $E_p = p^2 / (2m)$. The spectrum of the Hamiltonian is continuous but degenerate since $\phi_p$ and $\phi_{-p}$ have the same energy $E_p = E_{-p}$. Stationary solutions to Schrodinger's equation are therefore given by
    \[
        \psi_p(x, t) = \phi_p(x) e^{-iE_p t / \hbar} = \frac{1}{\sqrt{2\pi\hbar}} e^{i(px - E_p t) / \hbar}
    \]
\end{example}

\end{document}