\documentclass[12pt,a4paper]{article}
\AddToHook{cmd/section/before}{\clearpage}

\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts, amsmath, amssymb, amsthm}
\usepackage{diffcoeff}
\usepackage{hyperref}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[subsection]
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{example}[definition]{Example}
\newtheorem*{remark}{Remark}

\let\oldforall\forall
\renewcommand{\forall}{\ \oldforall}

\let\oldexist\exists
\renewcommand{\exists}{\ \oldexist}

\newcommand\existu{\ \oldexist!}

\title{Mathematical Physics Course Notes}
\author{Isaac Holt}

\begin{document}
\maketitle

\section{The action principle}

\subsection{Calculus of variatons}

\begin{definition}
	A \textbf{functional} is a map from a set of functions to $\mathbb{R}$, e.g. $f: (\mathbb{R} \rightarrow \mathbb{R}) \rightarrow \mathbb{R}$.
\end{definition}

\begin{definition}
	Let $y(t)$ be a function with fixed values at endpoints $a$ and $b$. $y$ is \textbf{stationary} for a functional $S$ if

	\[ \diff{S (y(t) + \epsilon z(t))}{\epsilon}\Big|_{\epsilon = 0} = 0 \]
	for every smooth (continuous derivative to every order) $z(t)$ such that $z(a) = z(b) = 0$.
\end{definition}

\begin{remark}
	Functions $y(t)$ may be referred to as \textbf{paths} and so functions that satisfy the above definition are referred to as \textbf{stationary paths}.
\end{remark}

\begin{definition}
	Let $S$ be an \textbf{action functional} (or just \textbf{action}). \textbf{The action principle} states that the paths described by particles are stationary paths of $S$.

	Mathematically, given a particle moving in one dimension with position given by $x(t)$, for arbitrary smooth small deformations $\delta x(t)$ around the true path $x(t)$ (the path the particle follows):

	\[ \delta S := S(x + \delta x) - S(x) = O({(\delta x)}^2) \]
\end{definition}

\begin{lemma}
	(Fundamental lemma of the calculus of variations) Let $f(x)$ be a continuous function in the interval $[a, b]$ such that

	\[ \int_a^b f(x) g(x) dx = 0 \]
	for every smooth function $g(x)$ in $[a, b]$ such that $g(a) = g(b) = 0$. Then $f(x) = 0 \forall x \in [a, b]$.
\end{lemma}

\begin{definition}
	Let $L(r, s)$ be a function of two real variables. If a functional $S$ can be expressed as the time integral of $L$, i.e. if

	\[ S(x) = \int_{t_0}^{t_1} L(x(t), \dot{x}(t)) dt \]
	then $L$ is called a \textbf{Lagrangian}.
\end{definition}

\begin{definition}
	For a Lagrangian $L$, the \textbf{Euler-Lagrange equation} is given by

	\[ \diffp{L}{x} - \diff{}{t} \left( \diffp{L}{\dot{x}} \right) = 0 \]
	where

	\[ \diffp{L}{x} = \diffp{L(r, s)}{r} \Big|_{(r, s) = (x(t), \dot{x}(t))} \text{ \ and \ } \diffp{L}{\dot{x}} = \diffp{L(r, s)}{s} \Big|_{(r, s) = (x(t), \dot{x}(t))} \]
\end{definition}

\begin{remark}\label{rem:lagrangianParametersIndependent}
	The Lagrangian $L$ is just an ordinary function of (here) two independent parameters $(r, s)$t. When constructing the action, $L$ is evaluated at $(r, s) = (x(t), \dot{x}(t))$, but $r$ and $s$ as parameters in the definition of the Lagrangian are independent.

	So $\dot{x}$ is treated as a variable which does not depend on $x$:

	\[ \diffp{x}{\dot{x}} = \diffp{\dot{x}}{x} = 0 \]
\end{remark}

\begin{remark}
	The Euler-Lagrange equation only applies to one-dimensional cases.
\end{remark}

\subsection{Configuration space and generalised coordinates}

\begin{definition}
	\textbf{Configuration space}, denoted $C$, is the set of all possible (in principle) instantaneous configurations for a given a physical system.
\end{definition}

\begin{remark}
	This definition includes positions, but does not include velocities.
\end{remark}

\begin{remark}
	A configuration space must be constructed before a Lagrangian is constructed. The Lagrangian describes the dynamics of this configuration space.
\end{remark}

\begin{example}
	A particle moving in $\mathbb{R}^d$ has configuration space $\mathbb{R}^d$.
\end{example}

\begin{example}
	$N$ distinct particles moving in $\mathbb{R}^d$ have configuration space ${(\mathbb{R}^d)}^N = \mathbb{R}^{dN}$. The configuration space would still be $\mathbb{R}^{dN}$ if the particles were electrically charged, as the charge of the particles does not affect their positions, at least initially.
\end{example}

\begin{example}
	Two distinct particles joined by a rigid rod have configuration space $\mathbb{R}^{2d - 1}$. One particle has configuration space $\mathbb{R}^d$ and there are $d - 1$ angles that must specified to choose the position of the second particle relative to the other.
\end{example}

\begin{definition}
	Let $S$ be a physical system with configuration space $C$. Then $S$ has $\dim(C)$ \textbf{degrees of freedom}.
\end{definition}

\begin{remark}
	For every configuration space, any choice of coordinate system is valid, and the Lagrangian formalism holds regardless of this choice.
\end{remark}

\begin{definition}
	For a configuration space $C$, a set of coordinates in this space is called a set of \textbf{generalised coordinates}. Often generalized coordinates are represented with $q_i$, $i \in \{ 1, \dots, \dim(C) \}$ where $\underline{q}$ is the coordinate vector with components $q_i$.
\end{definition}

\begin{example}
	A particle moving in $\mathbb{R}^2$, with configuration space $\mathbb{R}^2$. We could use Cartesian or polar coordinates to describe the position of the particle in this space (both are equally valid).
\end{example}

\begin{definition}
	Let $C$ be a configuration space and let $\underline{q}(t) \in C$ be a path. For a Lagrangian function $L(\underline{q}, \underline{\dot{q}})$, the \textbf{Euler-Lagrange equations} state that

	\[ \diffp{L}{q_i} - \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) = 0 \quad \forall i \in \{ 1, \dots, \dim(C) \} \]
\end{definition}

\begin{remark}
	The Euler-Lagrange equations are valid in any coordinate system.
\end{remark}

\begin{remark}
	Similarly to the one-dimensional case:

	\[ \diffp{q_i}{\dot{q}_j} = \diffp{\dot{q}_i}{q_j} = 0 \]
	and

	\[ \diffp{q_i}{q_j} = \diffp{\dot{q}_i}{\dot{q}_j} = \delta_{ij} \]
\end{remark}

\subsection{Lagrangians for classical mechanics}

\begin{definition}
	In a system with kinetic energy $T(\underline{q}, \underline{\dot{q}})$ and potential energy $V(\underline{q})$, the Lagrangian that describes the equations of motion in that system is given by

	\[ L(\underline{q}, \underline{\dot{q}}) = T(\underline{q}, \underline{\dot{q}}) - V(\underline{q}) \]
\end{definition}

\subsection{Ignorable coordinates and conservation of generalised momenta}

\begin{definition}
	Let $\{ q_1, \dots, q_N \}$ be a set of generalised coordinates. A specific coordinates $q_i$ is \textbf{ignorable} if the Lagrangian function expressed in these generalised coordinates does not depend on $q_i$, i.e. if

	\[ \diffp{L}{q_i} = 0 \]
\end{definition}

\begin{definition}
	The \textbf{generalised momentum} $p_i$ associated with a generalised coordinate $q_i$ is given by

	\[ p_i := \diffp{L}{\dot{q_i}} \]
\end{definition}

\begin{proposition}\label{prop:generalisedIgnorableMomentumConserved}
	The generalised momentum associated to an ignorable coordinate is conserved.
\end{proposition}

\begin{proof}
	From the Euler-Lagrange equation for $q_i$,

	\[ 0 = \diff{}{t} \left( \diffp{L}{\dot{q_i}} \right) - \diffp{L}{q_i} = \diff{p_i}{t} - 0 = \diff{p_i}{t} \]
\end{proof}

\begin{example}
	For a free particle moving in $d$ dimensions, in Cartesian coordinates we have

	\[ L = T - V = \frac{1}{2} m \sum_{i = 1}^d \dot{x}_i^2 \]
	so every coordinate is ignorable. The generalised momenta are

	\[ p_i = \diffp{L}{\dot{x}_i} = m \dot{x}_i \]
	So here the conservation of generalised momenta is the conservation of the linear momenta.
\end{example}

\section{Symmetries, Noether's theorem and conservation laws}

\subsection{Ordinary symmetries}

\begin{definition}
	For a uniparametric family of smooth maps $\phi(\epsilon): C \rightarrow C$ from configuration space to itself, with $\phi(0)$ the identity map, this family of maps is called a \textbf{transformation depending on $\epsilon$}. In any coordinates system this transformation can be written as

	\[ q_i \rightarrow \phi_i(q_1, \dots, q_N, \epsilon) \]
	where the $\phi_i$'s are a set of $N := \dim(C)$ functions representing the transformation in the coordinate system. The change in velocities is defined as

	\[ \dot{q}_i \rightarrow \diff{}{t} \phi_i \]
\end{definition}

\begin{remark}
	$q_i'$ is used to denote $\phi(q_i, \epsilon)$, so often we write $q_i \rightarrow q_i' = \dots$, where $\dots$ is a function of $q_i$ and $\epsilon$.
\end{remark}

\begin{definition}
	The \textbf{generator} of $\phi$ is

	\[ \diff{\phi(\epsilon)}{\epsilon} \Big|_{\epsilon = 0} := \lim_{\epsilon \rightarrow 0} \frac{\phi(\epsilon) - \phi(0)}{\epsilon} \]
	In any coordinate system,

	\[ q_i \rightarrow \phi_i(\underline{q}, \epsilon) = q_i + \epsilon a_i(\underline{q}) + O(\epsilon^2) \]
	where

	\[ a_i = \diffp{\phi_i(\underline{q}, \epsilon)}{\epsilon} \Big|_{\epsilon = 0} \]
	is a function of the generalised coordinates. Hence the transformation generator is $a_i$. For the velocities the transformation is

	\[ \dot{q}_i \rightarrow \dot{q}_i + \epsilon a_i(q_1, \dots, q_N, \dot{q}_1, \dots, \dot{q}_N) + O(\epsilon^2) \]
	where the generator is $\dot{a}_i$.
\end{definition}

\begin{example}
	For a particle moving in two dimensions, the finite transformations given by rotations around the origin, in Cartesian coordinates, are
	\[
		\begin{aligned}
			& x \rightarrow x \cos(\epsilon) - y \sin(\epsilon) \\
			& y \rightarrow x \sin(\epsilon) + y \cos(\epsilon)
		\end{aligned}
	\]
	The associated infinitesimal transformations can be derived using the expansions $\sin(\epsilon) = \epsilon + O(\epsilon^3)$ and $\cos(\epsilon) = 1 + O(\epsilon^2)$. Then
	\[
		\begin{aligned}
			& x \rightarrow x - y \epsilon + O(\epsilon^2) \\
			& y \rightarrow y + x \epsilon + O(\epsilon^2)
		\end{aligned}
	\]
	Then the generators of the transformation are
	\[
		a_x = -y, \quad a_y = x, \quad \dot{a}_x = -\dot{y}, \quad \dot{a}_y = \dot{x}
	\]
\end{example}

\begin{lemma}
	Equations of motion do not change if the Lagrangian is modified by adding the total derivative of a function of coordinates and time, i.e.
	\[
		L \rightarrow L + \diff{F(q_1, \dots, q_N, t)}{t}
	\]
	results in the same equations of motion.
\end{lemma}

\begin{proof}
	The effect on the action is
	\[
		S = \int_{t_0}^{t_1} L dt \rightarrow S' = S + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)
	\]
	From the action principle, we must have that $\delta S$ vanishes to first order in $\delta q_i(t)$, with the $q_i$'s fixed at the path's endpoints. Therefore $F(q_1(t_1), \dots, q_N(t_1), t_1)$ and $F(q_1(t_0), \dots, q_N(t_0), t_0)$ are fixed. Hence
	\[
		\begin{aligned}
			\delta S' & = S'(\underline{q} + \delta \underline{q}) - S'(\underline{q}) \\
			& = (S(\underline{q} + \delta \underline{q}) + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)) \\
			& \quad - (S(\underline{q}) + F(q_1(t_1), \dots, q_N(t_1), t_1) - F(q_1(t_0), \dots, q_N(t_0), t_0)) \\
			& = S(\underline{q} + \delta\underline{q}) - S(\underline{q}) = \delta S
		\end{aligned}
	\]
	So the variation of the action is not affected, therefore the equations of motion cannot be affected.
\end{proof}

\begin{definition}
	A transformation $\phi(\epsilon)$ is a \textbf{symmetry} if, to first order in $\epsilon$, for some function $F(\underline{q}, t)$, the change in the Lagrangian is a total time derivative of $F(\underline{q}, t)$, i.e.

	\[
		L \rightarrow L + \epsilon \diff{F(\underline{q}, t)}{t} + O(\epsilon^2)
	\]
\end{definition}

\begin{remark}
	$F(\underline{q}, t)$ is only defined up to a constant. If some $F(\underline{q}, t)$ satisfies the above equation, then $G(\underline{q}, t) = F(\underline{q}, t) + c$ will also satisfy the equation.
\end{remark}

\begin{example}
	If $q_i$ is an ignorable coordinate, the transformation $q_i \rightarrow q_i + c_i$, where $c_i$ is a constant, is a symmetry, because $q_i$ does not appear in the Lagrangian by definition so here $F(\underline{q}, t) = 0$.
\end{example}

\begin{theorem}
	(Noether's theorem) In a given set of generalised coordinates, let $a_i(\underline{q})$ be the generator of a transformation such that
	\[
		L \rightarrow L + \epsilon \diff{F(\underline{q}, t)}{t} + O(\epsilon^2)
	\]
	so that it is a symmetry. Let
	\[
		Q := \left( \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right) - F
	\]
	Then $\diff{Q}{t} = 0$, so $Q$ is conserved. $Q$ is called the \textbf{Noether charge}.
\end{theorem}

\begin{proof}
	Consider the variation of the action under the transformation $q_i \rightarrow q_i + \epsilon a_i$. Using the chain rule and then the Euler-Lagrange equations,
	\[
		\begin{aligned}
			\delta S
				& = \int_{t_0}^{t_1} \sum{i = 1}^N \left( \epsilon a_i \diffp{L}{q_i} + \epsilon \dot{a}_i \diffp{L}{\dot{q}_i} \right) dt + O(\epsilon^2) \\
				& = \int_{t_0}^{t_1} \sum_{i = 1}^N \left( \epsilon a_i \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) + \epsilon \dot{a}_i \diffp{L}{\dot{q}_i} \right) + O(\epsilon^2) \\
				& = \int_{t_0}^{t_1} \epsilon \diff{}{t} \left( \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right) + O(\epsilon^2) \\
				& = \epsilon {\left[ \sum_{i = 1}^N a_i \diffp{L}{\dot{q}_i} \right]}_{t_0}^{t_1} + O(\epsilon^2)
		\end{aligned}
	\]
	Note that having used the Euler-Lagrange equations in the second line, the result is only valid along the path satisfying the equations of motion.

	Now since the transformation is a symmetry,
	\[
		\begin{aligned}
			\delta S
				& = S(\underline{q} + \delta \underline{q}) - S(\underline{q}) \\
				& = \int_{t_0}^{t_1} \left( \left( L + \epsilon \diff{F}{t} + O(\epsilon^2) \right) - L \right) \\
				& = \epsilon {[F]}_{t_0}^{t_1} + O(\epsilon^2)
		\end{aligned}
	\]
	Equating these two expressions for $\delta S$, we see that $Q(t_1) = Q(t_0)$. We didn't specify what $t_0$ and $t_1$ were so this equality holds for every $t_0$ and $t_1$. So let $t_1 = t_0 + \epsilon$, then
	\[
		Q(t_1) - Q(t_0) = Q(t_0 + \epsilon) - Q(t_0) = \epsilon \diff{Q}{t} + O(\epsilon^2) = 0
	\]
	hence $\diff{Q}{t} = 0$.
\end{proof}

\begin{example}
	If a coordinate $q_i$ is ignorable, there is a symmetry generated by $q_i \rightarrow q_i + \epsilon$ and leaving the other coordinates constant. So
	\[
		a_k = \delta_{ik} := \begin{cases}
			1 & \quad \text{if } i = k \\
			0 & \quad \text{otherwise}
		\end{cases}
	\]
	The Noether charge is
	\[
		Q = \sum_{k = 1}^{N} a_k \diffp{L}{\dot{q}_k} = \sum_{k = 1}^{N} \delta_{ik} \diffp{L}{\dot{q}_k} = \diffp{L}{\dot{q}_i}
	\]
	which agrees with Proposition \ref{prop:generalisedIgnorableMomentumConserved}.
\end{example}

\subsection{Energy conservation}

\begin{definition}
	Given a Lagrangian that explicitly depends on time, $L(\underline{q}, \underline{\dot{q}}, t)$, the \textbf{energy}, $E$, is defined as
	\[
		E := \left( \sum_{i = 1}^{N} \dot{q}_i \diffp{L}{\dot{q}_i} \right) - L
	\]
\end{definition}

\begin{theorem}
	Along a path $\underline{q}(t)$ which satisfies the equations of motion,
	\[
		\diff{E}{t} = -\diffp{L}{t}
	\]
\end{theorem}

\begin{proof}
	\[
		\begin{aligned}
			\diff{E}{t}
				& = \diff{}{t} \left( \left( \sum_{i = 1}^{N} \dot{q}_i \diffp{L}{\dot{q}_i} \right) - L \right) \\
				& = \sum_{i = 1}^{N} \left( \ddot{q}_i \diffp{L}{\dot{q}_i} + \dot{q}_i \diff{}{t} \left( \diffp{L}{\dot{q}_i} \right) \right) - \diff{L}{t} \\
				& = \sum_{i = 1}^{N} \left( \diffp{L}{\dot{q}_i} \ddot{q}_i + \dot{q}_i \diffp{L}{q_i} \right) - \diff{L}{t}
		\end{aligned}
	\]
	using the Euler-Lagrange equations. By the chain rule,
	\[
		\diff{L}{t} = \sum_{i = 1}^{N} \left( \diffp{L}{\dot{q}_i} + \diffp{L}{q_i} \dot{q}_i \right) + \diffp{L}{t}
	\]
	and so substituting this into the expression for $\diff{E}{t}$, we get
	\[
		\diff{E}{t} = -\diffp{L}{t}
	\]
\end{proof}

\begin{remark}
	Note that $\diffp{L}{t}$ means the partial derivative of $L$ with respect to $t$, \textbf{keeping $\underline{q}$ and $\underline{\dot{q}}$ fixed}. This is because the Lagrangian is (here) just an ordinary function of three parameters which are unrelated, so $t$ is independent of $\underline{q}$ and $\underline{\dot{q}}$. The parameters only become related when the Lagrangian is used to build the action. (See \hyperref[rem:lagrangianParametersIndependent]{this remark}).
\end{remark}

\begin{corollary}
	Energy is conserved iff the Lagrangian does not depend explicitly on time.
\end{corollary}

\begin{proof}
	Energy is conserved iff $\diff{E}{t} = 0$, and $\diffp{L}{t} = 0$ iff the Lagrangian does not depend explicitly on time.
\end{proof}

\section{Normal modes}

\subsection{Canonical kinetic terms}

\begin{definition}
	Given a Lagrangian $L = T - V$, $T$ is a \textbf{canonical} kinetic term if it is of the form
	\[
		T = \frac{1}{2} \sum_{i = 1}^{n} \dot{q}_i^2
	\]
\end{definition}

Given a Lagrangian with a canonical kinetic term, assume $\underline{q} = \underline{0}$ is a stationary point of $V(\underline{q})$, so
\[
	\diffp{V}{q_i} \Big|_{\underline{q} = 0} = 0 \quad \forall i \in \{ 1, \dots, n \}
\]

If $\underline{q} = \underline{0}$ is not a stationary point but $\underline{q} = \underline{a}$ for some $\underline{a}$ is, then the new variables defined as $q_i' = q_i - a_i$ are such that the stationary point is at $\underline{q}' = \underline{0}$. This preserves the form of the Lagrangian, so we can assume $\underline{q} = 0$ is a stationary point.

To determine the motion around this extremum, expand $V(\underline{q})$ to second order in $\underline{q}$ to define an approximate Lagrangian:
\[
	L_{\text{approx}} = \frac{1}{2} \sum_{i = 1}^{n} \dot{q}_i^2 - \frac{1}{2} \sum_{i, j} A_{i, j} q_i q_j
\]
where
\[
	A_{i, j} = \diffp[1, 1]V{q_i, q_j} \Big|_{\underline{q} = 0}
\]
The Euler-Lagrange equations for $L_{\text{approx}}$ are given in matrix notation by
\[
	\underline{\ddot{q}} + A \underline{q} = D_A \underline{q} = \left( \diff[2]{}{t} + A \right) \underline{q} = 0
\]
where $D_A$ is defined as $D_A := \diff[2]{}{t} + A$, which is a linear operator ($D_A (\underline{a} + \underline{b}) = D_A \underline{a} + D_A \underline{b}$ and $D_A (c \underline{a}) = c D_A \underline{a}$ for any vectors $a$ and $b$ and any $c \in \mathbb{R}$).

$A$ is an $n \times n$ matrix which is real and symmetric, due to symmetry of second partial derivatives (we assume $V$ has continuous second partial derivatives). So $A$ has $n$ real eigenvaules and eigenvectors. Let the eigenvalues be $\lambda^{(i)}$ and the corresponding eigenvectors be $\underline{v}^{(i)}$, then
\[
	A \underline{v}^{(i)} = \lambda^{(i)} \underline{v}^{(i)}
\]
Define the ansatz (an assumed solution)
\[
	\underline{q}^{(i)} (t) = f^{(i)} (t) \underline{v}^{(i)}
\]
for some function $f^{(i)} (t)$ to be determined. Then
\[
	\begin{aligned}
		\left( \diff[2]{}{t} + A \right) \underline{q}^{(i)} (t)
			& = \left( \diff[2]{}{t} + A \right) f^{(i)} (t) \underline{v}^{(i)}
			& = \underline{v}^{(i)} \left( \diff[2]{}{t} + \lambda^{(i)} \right) f^{(i)} (t)
			& = 0
	\end{aligned}
\]
and so since $\underline{v}^{(i)} \ne 0$,
\[
	\left( \diff[2]{}{t} + \lambda^{(i)} \right) f^{(i)} (t) = 0
\]
The solution to this equation is
\[
	f^{(i)} (t) = \begin{cases}
		\alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) & \quad \text{if } \lambda^{(i)} > 0 \\
		C^{(i)} t + D^{(i)} & \quad \text{if } \lambda^{(i)} = 0 \\
		\alpha^{(i)} \cosh(\sqrt{-\lambda^{(i)}} t) + \beta^{(i)} \sinh(\sqrt{-\lambda^{(i)}} t) & \quad \text{if } \lambda^{(i)} < 0 \\
	\end{cases}
\]
where $\alpha^{(i)}, \beta^{(i)}, C^{(i)}, D^{(i)}$ are constants determined by initial conditions.

The behaviour this solution describes depends on the sign of the $\lambda^{(i)}$. If every $\lambda^{(i)}$ is positive, there is a local minimum and there are oscillations around this minimum. If there is a negative eigenvalue, there is exponential behaviour away from the stationary point, which matches with the intuitioin that small perturbations at a maximum will quickly grow. Zero eignvaleues correspond with motion with constant velocity, with no oscillations.

The general solution is
\[
	\underline{q}(t) = \sum_{i = 1}^{N} \underline{v}^{(i)} f^{(i)} (t)
\]

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} > 0$, a \textbf{normal mode} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( \alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) \right)
	\]
\end{definition}

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} = 0$, a \textbf{zero mode} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( C^{(i)} t + D^{(i)} \right)
	\]
\end{definition}

\begin{definition}
	Given an eigenvalue $\lambda^{(i)} < 0$, an \textbf{instability} is a solution to
	\[
		\underline{q}(t) = \underline{v}^{(i)} \left( \alpha^{(i)} \cosh(\sqrt{-\lambda^{(i)}} t) + \beta^{(i)} \sinh(\sqrt{-\lambda^{(i)}} t) \right)
	\]
\end{definition}

\begin{definition}
	When there are no instabilities, the general solution is the superposition of normal modes for non-zero eigenvalues and zero modes:
	\[
		\underline{q}(t) = \sum_{i = 1, \ \lambda^{(i)} \ne 0}^{n} \underline{v}^{(i)} \left( \alpha^{(i)} \cos(\sqrt{\lambda^{(i)}} t) + \beta^{(i)} \sin(\sqrt{\lambda^{(i)}} t) \right) + \sum_{i = 1, \ \lambda^{(i)} = 0}^{n} \underline{v}^{(i)} \left( C^{(i)} t + D^{(i)} \right)
	\]
\end{definition}

\section{Hamiltonian Formalism}

\begin{definition}
	The classical \textbf{state} of a system at a given instant in time is a \textbf{complete} set of data that fully specifies the future evolution of the system.
\end{definition}

\begin{remark}
	\textbf{Any} set of data that fully fixes future evolution is valid.
\end{remark}

\begin{definition}
	The \textbf{phase (or state) space} is the set of all possible states for a system at a given time.
\end{definition}

\begin{example}
	A free particle moving in $\mathbb{R}$. The phase space is $\mathbb{R}^2$ ($\mathbb{R}$ for position, $\mathbb{R}$ for velocity).
\end{example}

\begin{definition}
	The \textbf{Hamiltonian formalism} studies dynamics in a phase space, parameterised by $\underline{q}(t)$ and $\underline{p}(t)$, where $p_i = \diffp{L}{\dot{\underline{q_i}}}$, the momentum.
\end{definition}

\begin{example}
	A particle moving in $\mathbb{R}$, with $L(x, \dot{x}) = \frac{1}{2} m \dot{x}^2$.

	Then $p_x = \diffp{L}{\dot{x}} = m \dot{x}$ so $\dot{x}(x, p_x) = \frac{p_x}{m}$.

	In the Hamltonian formalism, $L(x, p_x) = \frac{p_x^2}{2m}$.
\end{example}

\begin{example}
	A particle moving in $\mathbb{R}^2$ (in polar coordinates).

	$L(r, \theta, \dot{r}, \dot{\theta}) = \frac{1}{2} m (\dot{r}^2 + r^2 \dot{\theta}^2)$. So $p_r = m\dot{r}$ and $p_{\theta} = m r^2 \dot{\theta}$.

	So $\dot{r}(r, \theta, p_r, p_{\theta}) = \frac{p_r}{m}$, $\dot{\theta}(r, \theta, p_r, p_{\theta}) = \frac{p_{\theta}}{m r^2}$.

	$L(r, \theta, \dot{r}, \dot{\theta}) = L(r, \theta, p_r, p_{\theta}) = \frac{1}{2} (\frac{p_r^2}{m} + \frac{p_{\theta}^2}{m r^2})$.
\end{example}

\begin{definition}
	Given two functions $f(\underline{q}, \underline{p}, t)$ and $g(\underline{q}, \underline{p}, t)$ in phase space their \textbf{Poisson bracket} is:

	\[ \{f, g\} := \sum_{i = 1}^n \left( \diffp{f}{q_i} \diffp{g}{p_i} - \diffp{f}{p_i} \diffp{g}{q_i} \right)\] where $n$ is the dimension of the configuration space.
\end{definition}

\begin{remark}
	In the Hamiltonian formalism, $\diffp{q_i}{p_j} = \diffp{p_j}{q_i} = 0$.

	Similarly, $\diffp{q_i}{q_j} = \diffp{p_i}{p_j} = \delta_{i, j}$
\end{remark}

\begin{example}
	Let $f = q_i$, $g = q_j$. $\{q_i, q_j\} = 0$, and $\{p_i, p_j\} = 0$. $\{q_i, p_j\} = \sum_{k = 1}^n \delta_{i, j} \delta_{j, k} = \delta_{i, j}$.
\end{example}

\begin{definition}
	Let $\mathbb{F}$ be the set functions from a phase space $P$ to $\mathbb{R}$
\end{definition}

\begin{definition}
	The Hamiltonian flow $\Phi_f^{(s)}$, with $(s) \in \mathbb{R}$, $f \in F$ operator maps $\mathbb{F}$ to $\mathbb{F}$ and is defined as

	\[ \Phi_f^{(s)} (g) := e^{s \{\cdot, f\}} g := g + s \{g, f\} + \frac{s^2}{2} \{ \{g, f\}, f\} + \cdots \]
\end{definition}

\begin{remark}
	The transformation generated by $f$ has generator $a_i = \{q_i, f\}$ where $q_i \rightarrow q_i + \epsilon a_i$.

	Infinitesimally, $\Phi_f^{(s)} (g) := g + \epsilon \{g, f\} + O(\epsilon^2)$
\end{remark}

TODO: properties on poisson bracket

\begin{example}
	(Rotation in $\mathbb{R}^2$ in Cartesian coordinates) As a guess, choose $f = q_1 \dot{q_2} - \dot{q_1} q_2$, the angular momentum.

	$L = \frac{1}{2} (\dot{q_1}^2 + \dot{q_2}^2) - V(q_1, q_2)$ so $p_1 = \diffp{L}{\dot{q_1}} = \dot{q_1}$ and $p_2 = \diffp{L}{\dot{q_2}} = \dot{q_2} \Rightarrow f = q_1 p_2 - q_2 p_1$.

	Then $q_1 \rightarrow q_1 + \epsilon \{ q_1, f \} + O(\epsilon^2) = q_1 + \epsilon \{ q_1, q_1 p_2 - q_2 p_1 \} = q_1 + \epsilon \{ q_1, q_1 p_2 \} - \epsilon \{ q_1, q_2 p_1 \} = q_1 + \epsilon \{q_1, q_1\} p_2 + \epsilon \{q_1, p_2\} q_1 - \epsilon \{q_1, q_2\} p_1 - \epsilon \{q_1, p_1\} q_2 = q_1 - \epsilon q_2$

	Similarly, $q_2 \rightarrow q_2 + \epsilon q_1$ so $(q_1, q_2) \rightarrow (q_1, q_2) + \epsilon ((0, -1), (1, 0)) (q_1, q_2)$ TODO make into matrices and column vectors.
\end{example}

\begin{definition}
	The \textbf{Hamiltonian} is the energy expressed in Hamiltonian coordinates:

	\[ H = \sum_{i = 1}^n \dot{q_i(\underline{q}, \underline{p})} p_i - L(\underline{q}, \dot{\underline{q}} (\underline{q}, \underline{p})) \]
\end{definition}

\begin{example}
	(Harmonic oscillator in one dimension) Let $\frac{1}{2} m \dot{x}^2 - \frac{1}{2} k x^2 \Rightarrow p = m\dot{x} \Rightarrow \dot{x} = \frac{p}{m}$.

	$H = \dot{x} p - L = \frac{p^2}{m} - (\frac{1}{2} \frac{p^2}{m} - \frac{1}{2} k x^2) = \frac{1}{2} \frac{p^2}{m} + \frac{1}{2} k x^2$
\end{example}

\begin{theorem}
	The time evolution of the phase space coordinates $\underline{q}, \underline{p}$ is generated by Hamiltonian flow $\Phi_H$:

	\[ q_i(t + a) = \Phi_H^{(a)} q_i(t), p_i(t + a) = \Phi_H^{(a)} p_i(t) \]
	Infinitesimally, $q_i(t) + \epsilon \dot{q_i}(t) + O(\epsilon^2) = q_i(t + \epsilon) = q_i(t) + \epsilon \{ q_i, H \} + O(\epsilon^2) \Leftrightarrow \dot{q_i} = \{q_i, H \} = \diffp{H}{p_i}$ and similarly, $\dot{p_i} = \{ p_i, H \} = -\diffp{H}{q_i}$.
	
	These equations are called \textbf{Hamilton's equations}.
\end{theorem}

\begin{proof}
	$\diffp{H}{q_i}$. TODO: complete this proof, finish rest of notes from lecture.
\end{proof}

\begin{corollary}
	The time evolution of any function $f(\underline{q}, \underline{p})$ in phase space is generated by $\Phi_H$:

	\[ \diff{f}{t} = \{ f, H \} \]
	If $f(\underline{q}, \underline{p}, t)$ depends explicitly on time then

	\[ \diff{f}{t} = \{ f, h \} + \diffp{f}{t} \]
\end{corollary}

\begin{proof}
	$\diff{f}{t} = \sum_{i = 1}^n \left( \diffp{f}{q_i} \dot{q_i} + \diffp{f}{p_i} \dot{p_i} \right) + \diffp{f}{t} = \sum_{i = 1}^n \left( \diffp{f}{q_i} \diffp{H}{p_i} - \diffp{f}{p_i} \diffp{H}{q_i} \right) + \diffp{f}{t} = \{ f, H \} + \diffp{f}{t}$.
\end{proof}

\section{Quantum mechanics introduction}

\begin{definition}
	The \textbf{photo-electric effect} is the phenomena where, when a light source is shone on a metal, electrons are released from the surface of the metal.
\end{definition}

\begin{definition}
	The \textbf{classical} description of light would lead to these results:
	\begin{itemize}
		\item The energy of the released electrons depends on the intensity of light $I$ but is independent of the angular frequency of the light, $\omega$.
		\item Electrons are released for any value of $I$
	\end{itemize}
\end{definition}

\begin{definition}
	The quantum mechanics prediction of the photoelectric effect is that the energy of the electrons $E$ is independent of $I$, and not released at all below some value of angular frequency.

	This led to the discovery that light consists of packets (photons).
\end{definition}

\section{The wave function and probabilities}

\begin{definition}
	The \textbf{wave function} is a function of position $x$ and time $t$:
	\[
		\psi: \mathbb{R}^2 \rightarrow \mathbb{C}
	\]
\end{definition}

\begin{remark}
	We require that $\psi$ is continuous, and that $\diff{\psi(x)}{x}$ is continuous ($\psi$ must be differentiable), except when the potential energy $V(x)$ is not finite. 
\end{remark}

\begin{definition}
	The \textbf{probability density} of finding a particle at position $x$ and time $t$ is defined as
	\[
		P(x, t) := |\psi(x, t)|^2
	\]

	The probability of finding the particle at $x \in [a, b]$ is therefore
	\[
		\int_a^b |\psi(x, t)|^2 dx
	\]
	The probability of finding the particle anywhere is must be equal to $1$, which means that
	\[
		\int_{-\infty}^{\infty} P(x, t) dx = 1 \quad \forall t \in \mathbb{R}
	\]
	This puts a constraint on $\psi$.
\end{definition}

\begin{definition}
	A wave function $\psi$ is \textbf{square-normalisable} if the integral
	\[
		\int_{-\infty}^{\infty} P(x, t) dx
	\]
	exists.
\end{definition}

\begin{definition}
	A wave function $\psi$ is \textbf{normalised} if
	\[
		\int_{-\infty}^{\infty} P(x, t) dx = 1 \quad \forall t \in \mathbb{R}	
	\]
\end{definition}

\begin{definition}
	For a given time $t$, the \textbf{expectation} value of a polynomial function $f(x)$ of position $x$, is defined as
	\[
		\langle f(x) \rangle := \int_{-\infty}^{-\infty} P(x, t) f(x) dx
	\]
\end{definition}

\begin{remark}
	The expectation of position, $\langle x \rangle$ is the mean of measurements of the positions of many particles with wave function $\psi$.
\end{remark}

\begin{definition}
	The \textbf{uncertainty} of $x$ is defined as
	\[
		\Delta x = \sqrt{\langle x^2 \rangle - \langle x \rangle ^2}
	\]
\end{definition}

\subsection{Examples of wave functions}

\begin{remark}
	For now, we will look at wave functions at a fixed time, $\psi(x)$.
\end{remark}

\begin{definition}
	The \textbf{Gaussian wave function} is defined as
	\[
		\psi(x) = C e^{-x^2 / 4 \Delta^2}
	\]
	where $\Delta > 0$ has units of length and $C$ is a normalisation constant.
	\[
		\int_{-\infty}^{\infty} |\psi(x)|^2 = 1
	\]
	so $C = e^{i \theta} {(2 \pi \Delta^2)}^{-1/4}$, with $\theta \in \mathbb{R}$. $\theta$ is a free parameter here, so is often set to $0$.

	So the normalised probability distribution is
	\[
		P(x) = \frac{1}{\sqrt{2 \pi \Delta^2}} e^{-x^2 / (2 \Delta^2)}
	\]
	which is a standard Gaussian probability distribution.
\end{definition}

\begin{remark}
	For the Gaussian wave function:
	\begin{itemize}
		\item $\langle x^{2n + 1} \rangle \ \forall n \in \mathbb{N}_0$ since the integral is an odd function of $x$ over a symmetric interval.
		\item As $\Delta$ is the only quantity with units of length and $x$ has units of length, $\langle x^{2n} \rangle \propto \Delta^{2n} \ \forall n \in \mathbb{N}_0$.
		\item $\langle x^2 \rangle = \Delta^2 \Longrightarrow \Delta x = \Delta$.
	\end{itemize}
\end{remark}

\begin{definition}
	If a particle's position $x$ is confined to $0 < x < L$, particle is said to be in an \textbf{infinite potential well}, defined as
	\[
		V(x) = \begin{cases}
			0 & \text{ if } 0 < x < L \\
			\infty & \text{ otherwise}
		\end{cases}
	\]
	To have position $x \le 0$ or $x \ge L$, the particle would need infinite energy, so the probability of finding it there is $0$, therefore the wave function for the particle should vanish in these regions.
\end{definition}

\begin{example}
	A possible wave function for a particle in an infinite potential well is
	\[
		\Psi(x) = \begin{cases}
			C \sqrt{x(L - x)} & \text{ if } 0 < x < L \\
			0 & \text{ otherwise }
		\end{cases}
	\]
	For some constant $C$. The probability of finding the particle anywhere in $(0, L)$ is $1$, so
	\[
		\int_{0}^{L} |\psi(x)|^2 dx = |C|^2 \int_{0}^{L} x(L - x) dx = |C|^2 \frac{L^3}{6} = 1
	\]
	which implies $C = \sqrt{6 / L^3} e^{i \theta}$ for any $\theta$. We choose $\theta = 0$ here.
\end{example}

\begin{remark}
	\textbf{Important:} multiplying a wave function $\psi(x)$ by $e^{i \theta}$ for any $\theta \in \mathbb{R}$ does not change the probability density function $P$, which means that measuring position cannot distinguish between $\psi(x)$ and $e^{i \theta} \psi(x)$.
	
	Measuring momentum can distinguish between these two, unless $\theta(x)$ is constant, in which case they cannot be distinguished by any measurement, and they describe the same physical state.
\end{remark}

\subsection{Collapse of the wave function}

\begin{definition}
	If a particle has a wave function $\psi(x, t)$ for $t < t_0$, then at $t = t_0$, the position $x$ is measured to be $x = x_0$. Then another measurement immediately after the first will be $x = x_0$ with probability $1$. This phenomenon is called the \textbf{wave function collapse}. Measuring $x$ changes the wave function so that it is very localised around $x_0$. This is why $\langle x \rangle$ is the average of measurements of many particles with the same wave function, not repeated measurements of the same wave function.
\end{definition}

\section{Momentum and Planck's constant}

\begin{definition}
	The \textbf{momentum operator} $\hat{p}$ is defined as
	\[
		\hat{p} (\psi(x)) := -i \hbar \diffp{}{x} (\psi(x))
	\]
	so that
	\[
		\begin{aligned}
			\delta_{\epsilon} \psi(x)
				& := \psi(x - \epsilon) - \psi(x) \\
				& = -\epsilon \diffp{}{x} \psi(x) + O(\epsilon^2) \\
				& = -\epsilon \frac{i}{\hbar} \hat{p} (\psi(x))
		\end{aligned}
	\]
	where $\hbar$ is a constant of proportionality.
\end{definition}

\begin{definition}
	In the above definition, $\hbar$ is called the \textbf{reduced Planck constant} which has units $\text{energy} \times \text{time}$. \textbf{Planck's constant} is defined as
	\[
		h = 2 \pi \hbar
	\]
\end{definition}

\begin{definition}
	We define a \textbf{position operator} $\hat{x}$ which multiplies a wave function by $x$:
	\[
		\hat{x} (\psi(x)) = x \psi(x)
	\]
\end{definition}

\begin{definition}
	The \textbf{commutator} of the position and momentum operators $\hat{x}$ and $\hat{p}$ is defined as
	\[
		\begin{aligned}
			\relax [\hat{x}, \hat{p}] (\psi(x))
				& = \hat{x} (\hat{p} (\psi(x))) - \hat{p} (\hat{x} (\psi(x))) \\
				& = \hat{x} \left( -i \hbar \diffp{}{x} \psi(x) \right)	+ i \hbar \diffp{}{x} (x \psi(x)) \\
				& = i \hbar \psi(x)
		\end{aligned}
	\]
	The relation $[\hat{x}, \hat{p}] (\psi(x)) = i \hbar \psi(x)$ is called the \textbf{canonical commutation relation}.
\end{definition}

\begin{remark}
	This commutator is similar to the Poisson bracket, where $\{ x, p \} = 1$ in classical mechanics. So we can transform a classical system into a quantum system by replacing the Poisson bracket $\{ , \}$ with $-\frac{i}{\hbar} [,]$. This replacement is called \textbf{canonical quantisation}.
\end{remark}

\begin{definition}
	The \textbf{expectation value of momentum}, $\langle p \rangle$ is defined as
	\[
		\begin{aligned}
			\langle p \rangle
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} \hat{p} (\psi(x, t)) dx \\
				& = -i \hbar \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx
		\end{aligned}
	\]
\end{definition}

\begin{remark}
	Notice the similarity between this definition and the one for the expectation value of position:
	\[
		\begin{aligned}
			\langle x \rangle
				& = \int_{-\infty}^{\infty} x |\psi(x, t)|^2 dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} \hat{x} (\psi(x, t)) dx
		\end{aligned}
	\]
	As with $\langle x \rangle$, $\langle p \rangle$ is interpreted as the average of measurements of the momenta of many particles with the same wave function $\psi$.
\end{remark}

\begin{proposition}
	$\hbar$ must be a real number (it is not complex).
\end{proposition}

\begin{proof}
	The measurement of momentum must be a real number, so $\langle p \rangle \in \mathbb{R}$. Using integration by parts and the fact that $|\psi(x, t)|^2$ vanishes as $x \rightarrow \pm \infty$ if $\psi$ is square normalisalbe, the complex conjuate of $\langle p \rangle$ is
	\[
		\begin{aligned}
			\overline{\langle p \rangle}
				& = i \bar{\hbar} \int_{-\infty}^{\infty} \psi(x, t) \diffp{}{x} \overline{\psi(x, t)} dx \\
				& = -i \bar{\hbar} \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx + i \hbar {[|\psi(x, t)|^2]}_{-\infty}^{\infty} \\
				& = -i \bar{\hbar} \int_{-\infty}^{\infty} \overline{\psi(x, t)} \diffp{}{x} \psi(x, t) dx \\
				& = \frac{\bar{\hbar}}{\hbar} \langle p \rangle
		\end{aligned}
	\]
	Therefore $\langle p \rangle \in \mathbb{R} \Longleftrightarrow \hbar \in \mathbb{R}$, so $\hbar$ must be real.
\end{proof}

\begin{definition}
	The \textbf{expectation value} of any polynomial $f$ of $p$ can be calculated as
	\[
		\begin{aligned}
			\langle f(p) \rangle
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} f(\hat{p}) \psi(x, t) dx \\
				& = \int_{-\infty}^{\infty} \overline{\psi(x, t)} f \left( -i \hbar \diffp{}{x} \right ) (\psi(x, t)) dx
		\end{aligned}
	\]
\end{definition}

\begin{definition}
	The \textbf{momentum uncertainty}, $\Delta p$ is defined as
	\[
		\Delta p = \sqrt{\langle p^2 \rangle - {\langle p \rangle}^2}
	\]
	This quantity describes the spread around $\langle p \rangle$ of measurements of the momenta of many particles with the same wave function $\psi$.
\end{definition}

\begin{example}
	For the Gaussian wave function, $\langle x \rangle = 0$ and $\langle x^2 \rangle = \Delta^2$ so the uncertainty in position is $\Delta x = \Delta$. The momentum operator applied to $\psi$ gives
	\[
		\begin{aligned}
			\hat{p} (\psi(x)) & = \frac{i \hbar}{2 \Delta^2} x \psi(x) \\
			\hat{p}^2 (\psi(x))
				& = -\hbar^2 \diffd[2]{}{x} (\psi(x)) \\
				& = \frac{\hbar^2}{2 \Delta^2} \psi(x) - \frac{\hbar^2}{4 \Delta^4} x^2 \psi(x)
		\end{aligned}
	\]
	Notice that the momentum operator always gives a polynomial in $x$ multiplied by $\psi(x)$, so we can use the position expectations to calculate the momentum expectations:
	\[
		\begin{aligned}
			\langle p \rangle & = \frac{i \hbar}{2 \Delta^2} \int_{-\infty}^{\infty} x |\psi(x)|^2 dx = \frac{i \hbar}{2 \Delta^2} \langle x \rangle = 0 \\
			\langle p^2 \rangle
				& = \frac{\hbar^2}{2 \Delta^2} \int_{-\infty}^{\infty} |\psi(x)|^2 dx - \frac{\hbar^2}{4 \Delta^4} \int_{-\infty}^{\infty} x^2 |\psi(x)|^2 dx \\
				& = \frac{\hbar^2}{2 \Delta^2} - \frac{\hbar^2}{4 \Delta^4} \langle x^2 \rangle \\
				& = \frac{\hbar^2}{2 \Delta^2} - \frac{\hbar^2}{4 \Delta^4} \Delta^2 \\
				& = \frac{\hbar^2}{4 \Delta^2}
		\end{aligned}
	\]
	So the uncertainty in momentum is
	\[
		\Delta p = \sqrt{\langle p^2 \rangle - {\langle p \rangle}^2} = \frac{\hbar}{2 \Delta}
	\]
	So the product of the uncertainties of position and momentum is a constant, independent of $\Delta$:
	\[
		\Delta x \Delta p = \frac{\hbar}{2}
	\]
	So as the uncertainty in position or momentum decreases, the other must increase.
\end{example}

\begin{definition}
	\textbf{Heisenberg's uncertainty principle} states that for every normalised wave function,
	\[
		\Delta x \Delta p \ge \frac{\hbar}{2}
	\]
\end{definition}

\begin{remark}
	Heisenberg's uncertainty principle shows that there is a limit on the how much the uncertainty in both position and momentum can be reduced.
\end{remark}

\begin{definition}
	A \textbf{minimal uncertainty wave function} is a wave function that minimises the quantity $\Delta x \Delta p$, i.e. $\Delta x \Delta p = \frac{\hbar}{2}$.
	
	The Gaussian wave function is an example of this.
\end{definition}

\end{document}